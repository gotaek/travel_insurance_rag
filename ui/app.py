"""
ì—¬í–‰ìë³´í—˜ RAG ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ UI
Streamlitì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°ë§ ë° ì¶”ì 
"""

import streamlit as st
import requests
import json
import time
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from typing import Dict, List, Any, Optional
import uuid
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì—¬í–‰ìë³´í—˜ RAG ëª¨ë‹ˆí„°ë§",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# API ê¸°ë³¸ ì„¤ì • - Docker í™˜ê²½ ê°ì§€
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000")

class RAGMonitor:
    """RAG ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.session_id = str(uuid.uuid4())
        self.conversation_history = []
        
    def send_question(self, question: str, include_context: bool = True) -> Dict[str, Any]:
        """ì§ˆë¬¸ì„ RAG APIë¡œ ì „ì†¡í•˜ê³  ê²°ê³¼ ë°˜í™˜"""
        try:
            response = requests.post(
                f"{API_BASE_URL}/rag/ask",
                json={
                    "question": question,
                    "session_id": self.session_id,
                    "include_context": include_context
                },
                timeout=120  # íƒ€ì„ì•„ì›ƒì„ 2ë¶„ìœ¼ë¡œ ì¦ê°€
            )
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    
    def get_trace(self) -> List[Dict[str, Any]]:
        """ìµœê·¼ ì‹¤í–‰ trace ì •ë³´ ì¡°íšŒ"""
        try:
            response = requests.get(f"{API_BASE_URL}/rag/trace")
            response.raise_for_status()
            data = response.json()
            return data.get("trace", [])
        except requests.exceptions.RequestException as e:
            st.error(f"Trace ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def get_session_info(self) -> Dict[str, Any]:
        """ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
        try:
            response = requests.get(f"{API_BASE_URL}/rag/session/{self.session_id}")
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException:
            return {}

def render_pipeline_flow(trace_data: List[Dict[str, Any]]) -> None:
    """íŒŒì´í”„ë¼ì¸ í”Œë¡œìš° ì‹œê°í™”"""
    if not trace_data:
        st.info("ì‹¤í–‰ëœ íŒŒì´í”„ë¼ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë…¸ë“œ ìˆœì„œ ì •ì˜
    node_order = [
        "planner", "websearch", "search", "rank_filter", 
        "verify_refine", "answer_qa", "answer_summary", 
        "answer_compare", "answer_recommend", "reevaluate", "replan"
    ]
    
    # ì‹¤í–‰ëœ ë…¸ë“œë“¤ë§Œ í•„í„°ë§
    executed_nodes = [node for node in trace_data if node.get("node") in node_order]
    
    if not executed_nodes:
        st.warning("ì‹¤í–‰ëœ ë…¸ë“œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í”Œë¡œìš° ì°¨íŠ¸ ìƒì„±
    fig = go.Figure()
    
    # ë…¸ë“œ ìœ„ì¹˜ ê³„ì‚°
    node_positions = {}
    for i, node_name in enumerate(node_order):
        if any(node["node"] == node_name for node in executed_nodes):
            node_positions[node_name] = (i, 0)
    
    # ë…¸ë“œ ê·¸ë¦¬ê¸°
    for node_name, (x, y) in node_positions.items():
        # ë…¸ë“œ ì •ë³´ ì°¾ê¸°
        node_info = next((node for node in executed_nodes if node["node"] == node_name), None)
        
        if node_info:
            # ì‹¤í–‰ ì‹œê°„ì— ë”°ë¥¸ ìƒ‰ìƒ ê²°ì •
            latency = node_info.get("latency_ms", 0)
            if latency > 5000:
                color = "red"
            elif latency > 2000:
                color = "orange"
            else:
                color = "green"
            
            # ë…¸ë“œ ì¶”ê°€
            fig.add_trace(go.Scatter(
                x=[x], y=[y],
                mode='markers+text',
                marker=dict(size=50, color=color, line=dict(width=2, color='black')),
                text=[node_name],
                textposition="middle center",
                name=node_name,
                hovertemplate=f"<b>{node_name}</b><br>" +
                             f"ì‹¤í–‰ì‹œê°„: {latency}ms<br>" +
                             f"ì…ë ¥í† í°: {node_info.get('in_tokens_approx', 0)}<br>" +
                             f"ì¶œë ¥í† í°: {node_info.get('out_tokens_approx', 0)}<extra></extra>"
            ))
    
    # ì—°ê²°ì„  ê·¸ë¦¬ê¸°
    for i in range(len(executed_nodes) - 1):
        current_node = executed_nodes[i]["node"]
        next_node = executed_nodes[i + 1]["node"]
        
        if current_node in node_positions and next_node in node_positions:
            x1, y1 = node_positions[current_node]
            x2, y2 = node_positions[next_node]
            
            fig.add_trace(go.Scatter(
                x=[x1, x2], y=[y1, y2],
                mode='lines',
                line=dict(color='gray', width=2),
                showlegend=False,
                hoverinfo='skip'
            ))
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        title="RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í”Œë¡œìš°",
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        showlegend=False,
        height=400,
        margin=dict(l=20, r=20, t=40, b=20)
    )
    
    st.plotly_chart(fig, use_container_width=True)

def render_performance_metrics(trace_data: List[Dict[str, Any]]) -> None:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì‹œê°í™”"""
    if not trace_data:
        return
    
    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
    df = pd.DataFrame(trace_data)
    
    # ì‹¤í–‰ ì‹œê°„ ì°¨íŠ¸
    fig_time = px.bar(
        df, 
        x='node', 
        y='latency_ms',
        title="ë…¸ë“œë³„ ì‹¤í–‰ ì‹œê°„ (ms)",
        color='latency_ms',
        color_continuous_scale='RdYlGn_r'
    )
    fig_time.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig_time, use_container_width=True)
    
    # í† í° ì‚¬ìš©ëŸ‰ ì°¨íŠ¸
    col1, col2 = st.columns(2)
    
    with col1:
        fig_tokens_in = px.bar(
            df, 
            x='node', 
            y='in_tokens_approx',
            title="ì…ë ¥ í† í° ìˆ˜",
            color='in_tokens_approx',
            color_continuous_scale='Blues'
        )
        fig_tokens_in.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig_tokens_in, use_container_width=True)
    
    with col2:
        fig_tokens_out = px.bar(
            df, 
            x='node', 
            y='out_tokens_approx',
            title="ì¶œë ¥ í† í° ìˆ˜",
            color='out_tokens_approx',
            color_continuous_scale='Greens'
        )
        fig_tokens_out.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig_tokens_out, use_container_width=True)

def render_document_analysis(passages: List[Dict[str, Any]]) -> None:
    """ê²€ìƒ‰ëœ ë¬¸ì„œ ë¶„ì„"""
    if not passages:
        st.info("ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.subheader("ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ ë¶„ì„")
    
    # ë¬¸ì„œ ì†ŒìŠ¤ë³„ ë¶„ë¥˜
    sources = {}
    for passage in passages:
        source = passage.get("source", "unknown")
        if source not in sources:
            sources[source] = []
        sources[source].append(passage)
    
    # ì†ŒìŠ¤ë³„ ë¬¸ì„œ ìˆ˜ í‘œì‹œ
    source_counts = {source: len(docs) for source, docs in sources.items()}
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ì†ŒìŠ¤ë³„ ë¬¸ì„œ ìˆ˜ ì°¨íŠ¸
        fig_sources = px.pie(
            values=list(source_counts.values()),
            names=list(source_counts.keys()),
            title="ë¬¸ì„œ ì†ŒìŠ¤ë³„ ë¶„í¬"
        )
        st.plotly_chart(fig_sources, use_container_width=True)
    
    with col2:
        # ë¬¸ì„œ ì ìˆ˜ ë¶„í¬
        scores = [p.get("score", 0) for p in passages]
        fig_scores = px.histogram(
            x=scores,
            title="ë¬¸ì„œ ê´€ë ¨ì„± ì ìˆ˜ ë¶„í¬",
            nbins=20
        )
        st.plotly_chart(fig_scores, use_container_width=True)
    
    # ë³´í—˜ì‚¬ë³„ ë¬¸ì„œ ë¶„ì„
    insurer_docs = {}
    for passage in passages:
        insurer = passage.get('insurer', 'Unknown')
        if insurer not in insurer_docs:
            insurer_docs[insurer] = []
        insurer_docs[insurer].append(passage)
    
    if insurer_docs:
        st.subheader("ğŸ¢ ë³´í—˜ì‚¬ë³„ ë¬¸ì„œ ë¶„í¬")
        
        # ë³´í—˜ì‚¬ë³„ ë¬¸ì„œ ìˆ˜
        insurer_counts = {insurer: len(docs) for insurer, docs in insurer_docs.items()}
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ë³´í—˜ì‚¬ë³„ ë¬¸ì„œ ìˆ˜ ì°¨íŠ¸
            fig_insurers = px.bar(
                x=list(insurer_counts.keys()),
                y=list(insurer_counts.values()),
                title="ë³´í—˜ì‚¬ë³„ ë¬¸ì„œ ìˆ˜",
                labels={'x': 'ë³´í—˜ì‚¬', 'y': 'ë¬¸ì„œ ìˆ˜'}
            )
            st.plotly_chart(fig_insurers, use_container_width=True)
        
        with col2:
            # ë³´í—˜ì‚¬ë³„ í‰ê·  ì ìˆ˜
            insurer_avg_scores = {}
            for insurer, docs in insurer_docs.items():
                avg_score = sum(d.get('score', 0) for d in docs) / len(docs)
                insurer_avg_scores[insurer] = avg_score
            
            fig_scores = px.bar(
                x=list(insurer_avg_scores.keys()),
                y=list(insurer_avg_scores.values()),
                title="ë³´í—˜ì‚¬ë³„ í‰ê·  ê´€ë ¨ì„± ì ìˆ˜",
                labels={'x': 'ë³´í—˜ì‚¬', 'y': 'í‰ê·  ì ìˆ˜'}
            )
            st.plotly_chart(fig_scores, use_container_width=True)
    
    # ìƒì„¸ ë¬¸ì„œ ì •ë³´
    st.subheader("ğŸ“‹ ë¬¸ì„œ ìƒì„¸ ì •ë³´")
    
    # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_passages = sorted(passages, key=lambda x: x.get('score', 0), reverse=True)
    
    for i, passage in enumerate(sorted_passages[:10]):  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
        # ë³´í—˜ì‚¬ ë¶€ìŠ¤íŠ¸ ì—¬ë¶€ í‘œì‹œ
        title_suffix = ""
        if passage.get('insurer_boost', False):
            title_suffix += " ğŸ¯"
        if passage.get('target_insurer', False):
            title_suffix += " â­"
        
        with st.expander(f"ë¬¸ì„œ {i+1}: {passage.get('title', 'ì œëª© ì—†ìŒ')} (ì ìˆ˜: {passage.get('score', 0):.3f}){title_suffix}"):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.write(f"**ì†ŒìŠ¤**: {passage.get('source', 'unknown')}")
                st.write(f"**ì ìˆ˜**: {passage.get('score', 0):.3f}")
            
            with col2:
                st.write(f"**í˜ì´ì§€**: {passage.get('page', 'N/A')}")
                st.write(f"**ë¬¸ì„œID**: {passage.get('doc_id', 'N/A')}")
            
            with col3:
                insurer = passage.get('insurer', 'N/A')
                insurer_display = insurer
                if passage.get('target_insurer', False):
                    insurer_display += " â­"
                st.write(f"**ë³´í—˜ì‚¬**: {insurer_display}")
                if passage.get('url'):
                    st.write(f"**URL**: {passage.get('url')}")
            
            # ë³´í—˜ì‚¬ ë¶€ìŠ¤íŠ¸ ì •ë³´
            if passage.get('insurer_boost', False):
                st.info("ğŸ¯ ì´ ë¬¸ì„œëŠ” ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰ëœ ë³´í—˜ì‚¬ì˜ ë¬¸ì„œë¡œ ìš°ì„ ìˆœìœ„ê°€ ë¶€ì—¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ë¬¸ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
            text = passage.get('text', '')
            if text:
                st.text_area(
                    "ë¬¸ì„œ ë‚´ìš©",
                    text[:500] + "..." if len(text) > 500 else text,
                    height=100,
                    disabled=True
                )

def render_conversation_history(monitor: RAGMonitor) -> None:
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ"""
    session_info = monitor.get_session_info()
    
    if not session_info or 'recent_turns' not in session_info:
        st.info("ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.subheader("ğŸ’¬ ëŒ€í™” íˆìŠ¤í† ë¦¬")
    
    turns = session_info.get('recent_turns', [])
    
    for turn in reversed(turns):  # ìµœì‹ ë¶€í„° í‘œì‹œ
        with st.expander(f"ì§ˆë¬¸: {turn.get('question', 'N/A')} ({turn.get('intent', 'unknown')})"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ì§ˆë¬¸**:")
                st.write(turn.get('question', 'N/A'))
            
            with col2:
                st.write("**ì˜ë„**:")
                st.write(turn.get('intent', 'unknown'))
            
            # ë‹µë³€ ì •ë³´
            result = turn.get('result', {})
            answer = None
            
            # final_answer ë˜ëŠ” draft_answerì—ì„œ ë‹µë³€ ì°¾ê¸°
            if result.get('final_answer'):
                answer = result['final_answer']
            elif result.get('draft_answer'):
                answer = result['draft_answer']
            
            if answer:
                st.write("**ë‹µë³€**:")
                st.write(answer.get('content', 'N/A'))
                
                # í’ˆì§ˆ ì ìˆ˜ í‘œì‹œ
                quality_score = result.get('quality_score', 0)
                if quality_score > 0:
                    st.write(f"**í’ˆì§ˆ ì ìˆ˜**: {quality_score:.2f}")
            else:
                st.write("**ë‹µë³€**: N/A")
            
            # ì‚¬ìš©ëœ ë¬¸ì„œ ìˆ˜
            passages_used = result.get('passages', [])
            st.write(f"**ì‚¬ìš©ëœ ë¬¸ì„œ ìˆ˜**: {len(passages_used)}")
            
            # í† í° ì‚¬ìš©ëŸ‰
            trace_data = result.get('trace', [])
            total_tokens = sum(node.get('out_tokens_approx', 0) for node in trace_data)
            st.write(f"**í† í° ì‚¬ìš©ëŸ‰**: {total_tokens}")

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    st.title("ğŸ›¡ï¸ ì—¬í–‰ìë³´í—˜ RAG ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§")
    st.markdown("---")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'monitor' not in st.session_state:
        st.session_state.monitor = RAGMonitor()
    
    monitor = st.session_state.monitor
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # API ì—°ê²° ìƒíƒœ í™•ì¸
        try:
            response = requests.get(f"{API_BASE_URL}/", timeout=5)
            if response.status_code == 200:
                st.success("âœ… API ì—°ê²°ë¨")
            else:
                st.error("âŒ API ì—°ê²° ì‹¤íŒ¨")
        except:
            st.error("âŒ API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        st.markdown("---")
        
        # ì„¸ì…˜ ì •ë³´
        st.subheader("ğŸ“Š ì„¸ì…˜ ì •ë³´")
        st.write(f"**ì„¸ì…˜ ID**: {monitor.session_id[:8]}...")
        
        session_info = monitor.get_session_info()
        if session_info:
            context = session_info.get('context', {})
            st.write(f"**ëŒ€í™” ìˆ˜**: {context.get('turn_count', 0)}")
            st.write(f"**ìƒì„± ì‹œê°„**: {context.get('created_at', 'N/A')}")
        
        st.markdown("---")
        
        # ìºì‹œ í†µê³„
        try:
            cache_response = requests.get(f"{API_BASE_URL}/rag/cache/stats")
            if cache_response.status_code == 200:
                cache_data = cache_response.json()
                st.subheader("ğŸ’¾ ìºì‹œ í†µê³„")
                cache_stats = cache_data.get('cache_stats', {})
                st.write(f"**ì„ë² ë”© ìºì‹œ**: {cache_stats.get('embeddings', 0)}")
                st.write(f"**ê²€ìƒ‰ ìºì‹œ**: {cache_stats.get('search', 0)}")
                st.write(f"**LLM ìºì‹œ**: {cache_stats.get('llm_response', 0)}")
        except:
            pass
    
    # ë©”ì¸ ì»¨í…ì¸ 
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” ì§ˆë¬¸í•˜ê¸°", "ğŸ“Š íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°ë§", "ğŸ“„ ë¬¸ì„œ ë¶„ì„", "ğŸ’¬ ëŒ€í™” íˆìŠ¤í† ë¦¬"])
    
    with tab1:
        st.header("ì§ˆë¬¸í•˜ê¸°")
        
        # ì§ˆë¬¸ ì…ë ¥
        question = st.text_area(
            "ì—¬í–‰ìë³´í—˜ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”:",
            placeholder="ì˜ˆ: í•´ì™¸ì—¬í–‰ ë³´í—˜ë£ŒëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
            height=100
        )
        
        col1, col2 = st.columns([1, 4])
        
        with col1:
            include_context = st.checkbox("ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬í•¨", value=True)
        
        with col2:
            if st.button("ì§ˆë¬¸í•˜ê¸°", type="primary"):
                if question.strip():
                    # ì§„í–‰ ìƒí™© í‘œì‹œ
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    try:
                        start_time = time.time()
                        
                        # ì§„í–‰ ìƒí™© í‘œì‹œ
                        status_text.text("ğŸ” ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                        progress_bar.progress(20)
                        
                        result = monitor.send_question(question, include_context)
                        
                        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                        status_text.text("ğŸ“Š íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                        progress_bar.progress(60)
                        end_time = time.time()
                        
                        progress_bar.progress(100)
                        status_text.text("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ!")
                        
                        if result:
                            # ë‹µë³€ í‘œì‹œ
                            st.success(f"ë‹µë³€ ìƒì„± ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ)")
                            
                            # ë‹µë³€ ë‚´ìš©
                            answer = None
                            if 'final_answer' in result and result['final_answer']:
                                answer = result['final_answer']
                                st.success("âœ… ìµœì¢… ë‹µë³€ (í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ)")
                            elif 'draft_answer' in result and result['draft_answer']:
                                answer = result['draft_answer']
                                st.warning("âš ï¸ ì´ˆì•ˆ ë‹µë³€ (í’ˆì§ˆ ê²€ì¦ ì¤‘)")
                            
                            if answer:
                                st.subheader("ë‹µë³€")
                                st.write(answer.get('content', 'ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'))
                                
                                # í’ˆì§ˆ ì ìˆ˜ í‘œì‹œ
                                quality_score = result.get('quality_score', 0)
                                st.write(f"**í’ˆì§ˆ ì ìˆ˜**: {quality_score:.2f}")
                                
                                # ì¸ìš© ì •ë³´
                                citations = answer.get('citations', [])
                                if citations:
                                    st.subheader("ì°¸ì¡° ë¬¸ì„œ")
                                    for i, citation in enumerate(citations):
                                        st.write(f"{i+1}. {citation.get('source', 'N/A')} (í˜ì´ì§€ {citation.get('page', 'N/A')})")
                            else:
                                st.error("ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            
                            # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                            monitor.conversation_history.append({
                                'question': question,
                                'result': result,
                                'timestamp': datetime.now()
                            })
                            
                            # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ëª¨ë‹ˆí„°ë§ íƒ­ ì—…ë°ì´íŠ¸
                            st.rerun()
                        else:
                            st.error("ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                            
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                        st.info("ğŸ’¡ **í•´ê²° ë°©ë²•**:")
                        st.write("1. ì§ˆë¬¸ì„ ë” ì§§ê²Œ ì…ë ¥í•´ë³´ì„¸ìš”")
                        st.write("2. API ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”")
                        st.write("3. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”")
                        
                        # ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
                        progress_bar.progress(0)
                        status_text.text("")
                else:
                    st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with tab2:
        st.header("íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°ë§")
        
        # ìµœê·¼ trace ì •ë³´ ì¡°íšŒ
        trace_data = monitor.get_trace()
        
        if trace_data:
            # íŒŒì´í”„ë¼ì¸ í”Œë¡œìš°
            st.subheader("ğŸ”„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í”Œë¡œìš°")
            render_pipeline_flow(trace_data)
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­
            st.subheader("ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­")
            render_performance_metrics(trace_data)
            
            # ìƒì„¸ trace ì •ë³´
            st.subheader("ğŸ” ìƒì„¸ ì‹¤í–‰ ì •ë³´")
            
            # Trace ë°ì´í„°í”„ë ˆì„
            df = pd.DataFrame(trace_data)
            st.dataframe(df, use_container_width=True)
            
            # ì´ ì‹¤í–‰ ì‹œê°„
            total_time = sum(node.get('latency_ms', 0) for node in trace_data)
            total_tokens = sum(node.get('out_tokens_approx', 0) for node in trace_data)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ ì‹¤í–‰ ì‹œê°„", f"{total_time}ms")
            with col2:
                st.metric("ì´ í† í° ìˆ˜", f"{total_tokens:,}")
            with col3:
                st.metric("ì‹¤í–‰ëœ ë…¸ë“œ ìˆ˜", len(trace_data))
            
            # re-evaluate ë…¸ë“œ ì •ë³´
            reevaluate_nodes = [node for node in trace_data if node.get('node_name') == 'reevaluate']
            if reevaluate_nodes:
                st.subheader("ğŸ” ë‹µë³€ í’ˆì§ˆ í‰ê°€")
                reevaluate_meta = reevaluate_nodes[0].get('reevaluate_meta', {})
                quality_score = reevaluate_meta.get('quality_score', 0)
                needs_replan = reevaluate_meta.get('needs_replan', False)
                replan_count = reevaluate_meta.get('replan_count', 0)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("í’ˆì§ˆ ì ìˆ˜", f"{quality_score:.2f}")
                with col2:
                    st.metric("ì¬ê²€ìƒ‰ í•„ìš”", "âœ…" if needs_replan else "âŒ")
                with col3:
                    st.metric("ì¬ê²€ìƒ‰ íšŸìˆ˜", f"{replan_count}/3")
                
                if needs_replan:
                    st.warning("âš ï¸ ë‹µë³€ í’ˆì§ˆì´ ê¸°ì¤€(0.7) ë¯¸ë§Œìœ¼ë¡œ ì¬ê²€ìƒ‰ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                else:
                    st.success("âœ… ë‹µë³€ í’ˆì§ˆì´ ê¸°ì¤€ì„ ë§Œì¡±í•©ë‹ˆë‹¤.")
        else:
            st.info("ì‹¤í–‰ëœ íŒŒì´í”„ë¼ì¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”.")
    
    with tab3:
        st.header("ë¬¸ì„œ ë¶„ì„")
        
        # ìµœê·¼ ì§ˆë¬¸ì˜ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„
        if monitor.conversation_history:
            latest_result = monitor.conversation_history[-1]['result']
            passages = latest_result.get('passages', [])
            
            if passages:
                render_document_analysis(passages)
            else:
                st.info("ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ì§ˆë¬¸ì„ ë¨¼ì € í•´ë³´ì„¸ìš”.")
    
    with tab4:
        st.header("ëŒ€í™” íˆìŠ¤í† ë¦¬")
        render_conversation_history(monitor)

if __name__ == "__main__":
    main()
