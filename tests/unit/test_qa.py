"""
QA ë…¸ë“œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
qa_nodeì˜ í•µì‹¬ ê¸°ëŠ¥ê³¼ ì—ëŸ¬ ì²˜ë¦¬ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
import os
import pytest
from unittest.mock import Mock, patch
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from graph.nodes.answerers.qa import qa_node, _format_context, _parse_llm_response


@pytest.mark.unit
class TestQANode:
    """QA ë…¸ë“œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def test_format_context_empty_passages(self):
        """ë¹ˆ íŒ¨ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        result = _format_context([])
        assert result == "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        print("âœ… ë¹ˆ íŒ¨ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬")
    
    def test_format_context_with_passages(self):
        """íŒ¨ì‹œì§€ í¬ë§·íŒ… í…ŒìŠ¤íŠ¸"""
        passages = [
            {
                "doc_id": "DBì†í•´ë³´í—˜_ì—¬í–‰ìë³´í—˜ì•½ê´€",
                "page": 15,
                "text": "í•­ê³µê¸° ì—°ì°©ìœ¼ë¡œ ì¸í•œ ì§€ì—° ì‹œ ìµœëŒ€ 24ì‹œê°„ê¹Œì§€ ì§€ì—°ë³´ìƒê¸ˆì„ ì§€ê¸‰í•©ë‹ˆë‹¤."
            },
            {
                "doc_id": "KBì†í•´ë³´í—˜_ì—¬í–‰ìë³´í—˜ì•½ê´€", 
                "page": 12,
                "text": "ì—¬í–‰ ì¤‘ ì§ˆë³‘ìœ¼ë¡œ ì¸í•œ ì˜ë£Œë¹„ëŠ” ì‹¤ì œ ë°œìƒí•œ ë¹„ìš©ì— ëŒ€í•´ ë³´ìƒí•©ë‹ˆë‹¤."
            }
        ]
        
        result = _format_context(passages)
        
        # ê²°ê³¼ì— í•„ìš”í•œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        assert "DBì†í•´ë³´í—˜_ì—¬í–‰ìë³´í—˜ì•½ê´€" in result
        assert "í˜ì´ì§€ 15" in result
        assert "KBì†í•´ë³´í—˜_ì—¬í–‰ìë³´í—˜ì•½ê´€" in result
        assert "í˜ì´ì§€ 12" in result
        assert "í•­ê³µê¸° ì—°ì°©" in result
        assert "ì˜ë£Œë¹„" in result
        
        print("âœ… íŒ¨ì‹œì§€ í¬ë§·íŒ…")
    
    def test_format_context_long_text_truncation(self):
        """ê¸´ í…ìŠ¤íŠ¸ ìë™ ì˜ë¦¼ í…ŒìŠ¤íŠ¸"""
        long_text = "ì—¬í–‰ìë³´í—˜" * 200  # ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸
        passages = [{
            "doc_id": "í…ŒìŠ¤íŠ¸_ë¬¸ì„œ",
            "page": 1,
            "text": long_text
        }]
        
        result = _format_context(passages)
        
        # 500ìë¡œ ì œí•œë˜ì–´ì•¼ í•¨
        assert len(result) < len(long_text)
        assert "ì—¬í–‰ìë³´í—˜" in result
        
        print("âœ… ê¸´ í…ìŠ¤íŠ¸ ìë™ ì˜ë¦¼")
    
    def test_parse_llm_response_valid_json(self):
        """ìœ íš¨í•œ JSON ì‘ë‹µ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        valid_response = {
            "conclusion": "í•­ê³µê¸° ì—°ì°© ì‹œ ì§€ì—°ë³´ìƒê¸ˆì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
            "evidence": ["DBì†í•´ë³´í—˜ ì•½ê´€ 15í˜ì´ì§€"],
            "caveats": ["ë³´í—˜ ê°€ì… í›„ 7ì¼ ëŒ€ê¸°ê¸°ê°„"],
            "quotes": []
        }
        
        json_text = json.dumps(valid_response, ensure_ascii=False)
        result = _parse_llm_response(json_text)
        
        assert result["conclusion"] == "í•­ê³µê¸° ì—°ì°© ì‹œ ì§€ì—°ë³´ìƒê¸ˆì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        assert "DBì†í•´ë³´í—˜ ì•½ê´€ 15í˜ì´ì§€" in result["evidence"]
        assert "ë³´í—˜ ê°€ì… í›„ 7ì¼ ëŒ€ê¸°ê¸°ê°„" in result["caveats"]
        
        print("âœ… ìœ íš¨í•œ JSON ì‘ë‹µ íŒŒì‹±")
    
    def test_parse_llm_response_markdown_json(self):
        """ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ê°ì‹¸ì§„ JSON íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        valid_response = {
            "conclusion": "í…ŒìŠ¤íŠ¸ ê²°ë¡ ",
            "evidence": ["í…ŒìŠ¤íŠ¸ ì¦ê±°"],
            "caveats": ["í…ŒìŠ¤íŠ¸ ì£¼ì˜ì‚¬í•­"],
            "quotes": []
        }
        
        markdown_json = f"```json\n{json.dumps(valid_response, ensure_ascii=False)}\n```"
        result = _parse_llm_response(markdown_json)
        
        assert result["conclusion"] == "í…ŒìŠ¤íŠ¸ ê²°ë¡ "
        
        print("âœ… ë§ˆí¬ë‹¤ìš´ JSON íŒŒì‹±")
    
    def test_parse_llm_response_invalid_json(self):
        """ì˜ëª»ëœ JSON ì‘ë‹µ fallback í…ŒìŠ¤íŠ¸"""
        invalid_response = "ì´ê²ƒì€ JSONì´ ì•„ë‹™ë‹ˆë‹¤"
        result = _parse_llm_response(invalid_response)
        
        # fallback êµ¬ì¡° í™•ì¸
        assert "conclusion" in result
        assert "evidence" in result
        assert "caveats" in result
        assert "quotes" in result
        assert "ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤" in result["conclusion"]
        
        print("âœ… ì˜ëª»ëœ JSON fallback")
    
    @patch('graph.nodes.answerers.qa.get_llm')
    def test_qa_node_success(self, mock_get_llm):
        """qa_node ì„±ê³µ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
        # Mock LLM ì„¤ì •
        mock_llm = Mock()
        mock_response = Mock()
        mock_response.text = json.dumps({
            "conclusion": "í•­ê³µê¸° ì—°ì°© ì‹œ ì§€ì—°ë³´ìƒê¸ˆì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
            "evidence": ["DBì†í•´ë³´í—˜ ì•½ê´€ 15í˜ì´ì§€"],
            "caveats": ["ë³´í—˜ ê°€ì… í›„ 7ì¼ ëŒ€ê¸°ê¸°ê°„"],
            "quotes": []
        }, ensure_ascii=False)
        mock_llm.generate_content.return_value = mock_response
        mock_get_llm.return_value = mock_llm
        
        # í…ŒìŠ¤íŠ¸ state
        state = {
            "question": "ë¹„í–‰ê¸° ì—°ì°© ì‹œ ë³´ì¥ ì•Œë ¤ì¤˜",
            "passages": [
                {
                    "doc_id": "DBì†í•´ë³´í—˜_ì—¬í–‰ìë³´í—˜ì•½ê´€",
                    "page": 15,
                    "text": "í•­ê³µê¸° ì—°ì°©ìœ¼ë¡œ ì¸í•œ ì§€ì—° ì‹œ ìµœëŒ€ 24ì‹œê°„ê¹Œì§€ ì§€ì—°ë³´ìƒê¸ˆì„ ì§€ê¸‰í•©ë‹ˆë‹¤."
                }
            ]
        }
        
        result = qa_node(state)
        
        # ê²°ê³¼ ê²€ì¦
        assert "draft_answer" in result
        assert "final_answer" in result
        assert result["draft_answer"]["conclusion"] == "í•­ê³µê¸° ì—°ì°© ì‹œ ì§€ì—°ë³´ìƒê¸ˆì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        assert "DBì†í•´ë³´í—˜ ì•½ê´€ 15í˜ì´ì§€" in result["draft_answer"]["evidence"]
        
        # LLM í˜¸ì¶œ í™•ì¸
        mock_llm.generate_content.assert_called_once()
        
        print("âœ… qa_node ì„±ê³µ ì¼€ì´ìŠ¤")
    
    @patch('graph.nodes.answerers.qa.get_llm')
    def test_qa_node_llm_failure(self, mock_get_llm):
        """qa_node LLM í˜¸ì¶œ ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸"""
        # Mock LLMì´ ì˜ˆì™¸ ë°œìƒí•˜ë„ë¡ ì„¤ì •
        mock_llm = Mock()
        mock_llm.generate_content.side_effect = Exception("LLM í˜¸ì¶œ ì‹¤íŒ¨")
        mock_get_llm.return_value = mock_llm
        
        # í…ŒìŠ¤íŠ¸ state
        state = {
            "question": "ë¹„í–‰ê¸° ì—°ì°© ì‹œ ë³´ì¥ ì•Œë ¤ì¤˜",
            "passages": []
        }
        
        result = qa_node(state)
        
        # fallback ë‹µë³€ í™•ì¸
        assert "draft_answer" in result
        assert "final_answer" in result
        assert "ì§ˆë¬¸ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤" in result["draft_answer"]["conclusion"]
        assert "LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤." in result["draft_answer"]["evidence"]
        assert "ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤." in result["draft_answer"]["caveats"]
        
        print("âœ… qa_node LLM ì‹¤íŒ¨ ì²˜ë¦¬")
    
    def test_qa_node_empty_question(self):
        """ë¹ˆ ì§ˆë¬¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        state = {
            "question": "",
            "passages": []
        }
        
        # LLM í˜¸ì¶œ ì—†ì´ í…ŒìŠ¤íŠ¸ (ì‹¤ì œë¡œëŠ” Mockì´ í•„ìš”í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” êµ¬ì¡°ë§Œ í™•ì¸)
        with patch('graph.nodes.answerers.qa.get_llm') as mock_get_llm:
            mock_llm = Mock()
            mock_response = Mock()
            mock_response.text = json.dumps({
                "conclusion": "ì§ˆë¬¸ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤",
                "evidence": [],
                "caveats": [],
                "quotes": []
            }, ensure_ascii=False)
            mock_llm.generate_content.return_value = mock_response
            mock_get_llm.return_value = mock_llm
            
            result = qa_node(state)
            
            assert "draft_answer" in result
            assert "final_answer" in result
            
        print("âœ… ë¹ˆ ì§ˆë¬¸ ì²˜ë¦¬")
    
    def test_qa_node_quotes_generation(self):
        """ì¶œì²˜ ì •ë³´ ìë™ ìƒì„± í…ŒìŠ¤íŠ¸"""
        with patch('graph.nodes.answerers.qa.get_llm') as mock_get_llm:
            mock_llm = Mock()
            mock_response = Mock()
            mock_response.text = json.dumps({
                "conclusion": "í…ŒìŠ¤íŠ¸ ê²°ë¡ ",
                "evidence": ["í…ŒìŠ¤íŠ¸ ì¦ê±°"],
                "caveats": ["í…ŒìŠ¤íŠ¸ ì£¼ì˜ì‚¬í•­"],
                "quotes": []
            }, ensure_ascii=False)
            mock_llm.generate_content.return_value = mock_response
            mock_get_llm.return_value = mock_llm
            
            state = {
                "question": "í…ŒìŠ¤íŠ¸ ì§ˆë¬¸",
                "passages": [
                    {
                        "doc_id": "DBì†í•´ë³´í—˜_ì—¬í–‰ìë³´í—˜ì•½ê´€",
                        "page": 15,
                        "text": "í•­ê³µê¸° ì—°ì°©ìœ¼ë¡œ ì¸í•œ ì§€ì—° ì‹œ ìµœëŒ€ 24ì‹œê°„ê¹Œì§€ ì§€ì—°ë³´ìƒê¸ˆì„ ì§€ê¸‰í•©ë‹ˆë‹¤."
                    },
                    {
                        "doc_id": "KBì†í•´ë³´í—˜_ì—¬í–‰ìë³´í—˜ì•½ê´€",
                        "page": 12,
                        "text": "ì—¬í–‰ ì¤‘ ì§ˆë³‘ìœ¼ë¡œ ì¸í•œ ì˜ë£Œë¹„ëŠ” ì‹¤ì œ ë°œìƒí•œ ë¹„ìš©ì— ëŒ€í•´ ë³´ìƒí•©ë‹ˆë‹¤."
                    }
                ]
            }
            
            result = qa_node(state)
            
            # quotes ìë™ ìƒì„± í™•ì¸
            quotes = result["draft_answer"]["quotes"]
            assert len(quotes) == 2  # ìƒìœ„ 2ê°œë§Œ
            assert "DBì†í•´ë³´í—˜_ì—¬í–‰ìë³´í—˜ì•½ê´€_í˜ì´ì§€15" in quotes[0]["source"]
            assert "KBì†í•´ë³´í—˜_ì—¬í–‰ìë³´í—˜ì•½ê´€_í˜ì´ì§€12" in quotes[1]["source"]
            
        print("âœ… ì¶œì²˜ ì •ë³´ ìë™ ìƒì„±")


@pytest.mark.benchmark
def test_qa_node_performance_benchmark():
    """QA ë…¸ë“œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("ğŸ¯ QA ë…¸ë“œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    print("="*60)
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        {
            "question": "ì—¬í–‰ìë³´í—˜ ë³´ì¥ ë‚´ìš©ì´ ë­ì•¼?",
            "passages": [
                {
                    "doc_id": "DBì†í•´ë³´í—˜_ì—¬í–‰ìë³´í—˜ì•½ê´€",
                    "page": 15,
                    "text": "í•­ê³µê¸° ì—°ì°©ìœ¼ë¡œ ì¸í•œ ì§€ì—° ì‹œ ìµœëŒ€ 24ì‹œê°„ê¹Œì§€ ì§€ì—°ë³´ìƒê¸ˆì„ ì§€ê¸‰í•©ë‹ˆë‹¤."
                }
            ]
        },
        {
            "question": "íœ´ëŒ€í’ˆ ë¶„ì‹¤ ì‹œ ë³´ìƒì€?",
            "passages": [
                {
                    "doc_id": "KBì†í•´ë³´í—˜_ì—¬í–‰ìë³´í—˜ì•½ê´€",
                    "page": 20,
                    "text": "íœ´ëŒ€í’ˆ ë¶„ì‹¤ ì‹œ ì‹¤ì œ ê°€ì¹˜ì— ë”°ë¼ ë³´ìƒê¸ˆì„ ì§€ê¸‰í•©ë‹ˆë‹¤."
                }
            ]
        },
        {
            "question": "ì˜ë£Œë¹„ ë³´ìƒ í•œë„ëŠ”?",
            "passages": [
                {
                    "doc_id": "ì‚¼ì„±í™”ì¬_ì—¬í–‰ìë³´í—˜ì•½ê´€",
                    "page": 25,
                    "text": "ì˜ë£Œë¹„ ë³´ìƒ í•œë„ëŠ” 1ì–µì›ê¹Œì§€ ë³´ì¥í•©ë‹ˆë‹¤."
                }
            ]
        }
    ]
    
    success_count = 0
    total_count = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            with patch('graph.nodes.answerers.qa.get_llm') as mock_get_llm:
                mock_llm = Mock()
                mock_response = Mock()
                mock_response.text = json.dumps({
                    "conclusion": f"í…ŒìŠ¤íŠ¸ {i} ë‹µë³€",
                    "evidence": [f"í…ŒìŠ¤íŠ¸ {i} ì¦ê±°"],
                    "caveats": [f"í…ŒìŠ¤íŠ¸ {i} ì£¼ì˜ì‚¬í•­"],
                    "quotes": []
                }, ensure_ascii=False)
                mock_llm.generate_content.return_value = mock_response
                mock_get_llm.return_value = mock_llm
                
                result = qa_node(case)
                
                # ê¸°ë³¸ êµ¬ì¡° í™•ì¸
                assert "draft_answer" in result
                assert "final_answer" in result
                assert "conclusion" in result["draft_answer"]
                
                success_count += 1
                print(f"âœ… í…ŒìŠ¤íŠ¸ {i}: {case['question'][:30]}...")
                
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ {i}: {case['question'][:30]}... - {str(e)}")
    
    success_rate = (success_count / total_count) * 100
    print(f"\nğŸ“Š ì„±ê³µë¥ : {success_count}/{total_count} ({success_rate:.1f}%)")
    
    if success_rate >= 90:
        print("ğŸ‰ ìš°ìˆ˜í•œ ì„±ëŠ¥!")
    elif success_rate >= 80:
        print("ğŸ‘ ì–‘í˜¸í•œ ì„±ëŠ¥")
    else:
        print("âš ï¸ ê°œì„  í•„ìš”")
    
    return success_rate


if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
    test_qa_node_performance_benchmark()
