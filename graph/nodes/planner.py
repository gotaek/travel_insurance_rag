from typing import Dict, Any, List, Optional
import json
import re
import logging
from app.deps import get_planner_llm
from graph.models import PlannerResponse
from graph.config_manager import get_system_config

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

INTENTS = ["summary", "compare", "qa", "recommend"]

# ë³´ìœ  ë³´í—˜ì‚¬ ëª©ë¡
OWNED_INSURERS = ["ì‚¼ì„±í™”ì¬", "ì¹´ì¹´ì˜¤í˜ì´", "í˜„ëŒ€í•´ìƒ", "DBì†í•´ë³´í—˜", "KBì†í•´ë³´í—˜"]

# ìƒë‹¨ì— ë³´ì¡° ë§µ ì¶”ê°€
ALIAS_MAP = {
    # ë³´ìœ  5ì‚¬ (ì •ì‹ëª… â†’ ë™ì¼, ì•½ì¹­/ì˜ë¬¸ â†’ ì •ì‹ëª…)
    "ì‚¼ì„±í™”ì¬": "ì‚¼ì„±í™”ì¬", "ì‚¼ì„±": "ì‚¼ì„±í™”ì¬", "samsung fire": "ì‚¼ì„±í™”ì¬", 
    "ì¹´ì¹´ì˜¤í˜ì´": "ì¹´ì¹´ì˜¤í˜ì´", "ì¹´ì¹´ì˜¤": "ì¹´ì¹´ì˜¤í˜ì´", "kakaopay": "ì¹´ì¹´ì˜¤í˜ì´", "kakao": "ì¹´ì¹´ì˜¤í˜ì´",
    "í˜„ëŒ€í•´ìƒ": "í˜„ëŒ€í•´ìƒ", "í˜„ëŒ€": "í˜„ëŒ€í•´ìƒ", "hyundai marine": "í˜„ëŒ€í•´ìƒ",
    "dbì†í•´ë³´í—˜": "DBì†í•´ë³´í—˜", "db": "DBì†í•´ë³´í—˜", "ë™ë¶€í™”ì¬": "DBì†í•´ë³´í—˜", "ë™ë¶€": "DBì†í•´ë³´í—˜",
    "kbì†í•´ë³´í—˜": "KBì†í•´ë³´í—˜", "kb": "KBì†í•´ë³´í—˜", "kbì†í•´": "KBì†í•´ë³´í—˜",

    # ë¹„ë³´ìœ  ì˜ˆì‹œ(í™•ì¥ ê°€ëŠ¥) â€” ì •ì‹ëª…/ì•½ì¹­ì„ ë™ì¼ canonicalë¡œ
    "í•œí™”ì†í•´ë³´í—˜": "í•œí™”ì†í•´ë³´í—˜", "í•œí™”": "í•œí™”ì†í•´ë³´í—˜",
    "ë©”ë¦¬ì¸ í™”ì¬": "ë©”ë¦¬ì¸ í™”ì¬", "ë©”ë¦¬ì¸ ": "ë©”ë¦¬ì¸ í™”ì¬",
    "ë¡¯ë°ì†í•´ë³´í—˜": "ë¡¯ë°ì†í•´ë³´í—˜", "ë¡¯ë°": "ë¡¯ë°ì†í•´ë³´í—˜",
    "nhì†í•´ë³´í—˜": "NHì†í•´ë³´í—˜", "nh": "NHì†í•´ë³´í—˜",
    "í¥êµ­í™”ì¬": "í¥êµ­í™”ì¬", "í¥êµ­": "í¥êµ­í™”ì¬",
    "axaì†í•´ë³´í—˜": "AXAì†í•´ë³´í—˜", "axa": "AXAì†í•´ë³´í—˜",
    "mgì†í•´ë³´í—˜": "MGì†í•´ë³´í—˜", "mg": "MGì†í•´ë³´í—˜",
    "ì‹ í•œì†í•´ë³´í—˜": "ì‹ í•œì†í•´ë³´í—˜", "ì‹ í•œ": "ì‹ í•œì†í•´ë³´í—˜",
    "í•˜ë‚˜ì†í•´ë³´í—˜": "í•˜ë‚˜ì†í•´ë³´í—˜", "í•˜ë‚˜": "í•˜ë‚˜ì†í•´ë³´í—˜",
}

# ì •ê·œì‹ íŒ¨í„´ìš© í›„ë³´(ê¸¸ì´ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì¤‘ë³µ/ê²¹ì¹¨ ë°©ì§€)
ALIAS_SORTED = sorted(ALIAS_MAP.keys(), key=len, reverse=True)

def _extract_insurers_from_question(question: str) -> List[str]:
    """
    ì§ˆë¬¸ì—ì„œ ë³´í—˜ì‚¬ ì—”í‹°í‹°(ì •ì‹ëª… canonical)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    - ê¸´ ë³„ì¹­ ìš°ì„  ë§¤ì¹­
    - ì•½ì¹­/ì˜ë¬¸ ë³„ì¹­ì„ ì •ì‹ëª…ìœ¼ë¡œ ì •ê·œí™”
    - í•œêµ­ì–´ ì¡°ì‚¬/ë¬¸ì¥ë¶€í˜¸ ê²½ê³„ í—ˆìš©
    - ì¤‘ë³µ ì œê±°, ê²¹ì¹¨ ë°©ì§€
    """
    q = question.lower()
    found = []
    used_spans = []  # (start, end)ë¡œ ê²¹ì¹¨ ë°©ì§€

    for alias in ALIAS_SORTED:
        # ê°„ë‹¨í•œ ë‹¨ì–´ ê²½ê³„ ê²€ìƒ‰
        if alias.lower() in q:
            # ê²¹ì¹¨ ë°©ì§€
            start_pos = q.find(alias.lower())
            end_pos = start_pos + len(alias.lower())
            
            # ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
            if any(not (end_pos <= s or e <= start_pos) for s, e in used_spans):
                continue
                
            canon = ALIAS_MAP[alias]
            found.append(canon)
            used_spans.append((start_pos, end_pos))

    # ìˆœì„œ ë³´ì¡´ ì¤‘ë³µ ì œê±°
    seen = set()
    dedup = []
    for c in found:
        if c not in seen:
            dedup.append(c)
            seen.add(c)
    return dedup

def _determine_insurer_filter_and_web_need(question: str) -> Dict[str, Any]:
    """
    ì¶”ì¶œ ê²°ê³¼ë¥¼ ë³´ìœ /ë¹„ë³´ìœ ë¡œ ë‚˜ëˆ„ê³ , filter/needs_webì„ ê²°ì •
    """
    extracted = _extract_insurers_from_question(question)

    if not extracted:
        return {
            "insurer_filter": None,
            "needs_web": False,
            "extracted_insurers": [],
            "owned_insurers": [],
            "non_owned_insurers": []
        }

    # ë³´ìœ /ë¹„ë³´ìœ  ë¶„ë¦¬
    owned = [c for c in extracted if c in OWNED_INSURERS]
    non_owned = [c for c in extracted if c not in OWNED_INSURERS]

    # í•˜ë‚˜ë¼ë„ ë¹„ë³´ìœ ê°€ ìˆìœ¼ë©´ ì›¹ í•„ìš”
    needs_web = len(non_owned) > 0

    # ë³´ìœ ì‚¬ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ filter, ì—†ìœ¼ë©´ None
    insurer_filter = owned if owned else None

    return {
        "insurer_filter": insurer_filter,
        "needs_web": needs_web,
        "extracted_insurers": extracted,
        "owned_insurers": owned,
        "non_owned_insurers": non_owned
    }

def _llm_classify_intent(question: str) -> Dict[str, Any]:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì˜ ë„ë©”ì¸ ê´€ë ¨ì„±, intentì™€ needs_webì„ ë¶„ë¥˜ (structured output ì‚¬ìš©)
    """
    prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì—¬í–‰ìë³´í—˜ RAG ì‹œìŠ¤í…œì—ì„œ ì ì ˆí•œ ì²˜ë¦¬ ë°©ì‹ì„ ê²°ì •í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: "{question}"

ë¨¼ì € ì´ ì§ˆë¬¸ì´ ì—¬í–‰ì ë³´í—˜ ë„ë©”ì¸ê³¼ ê´€ë ¨ëœì§€ íŒë‹¨í•˜ì„¸ìš”:
- ì—¬í–‰ì ë³´í—˜, í•´ì™¸ì—¬í–‰ë³´í—˜, ë³´í—˜ë£Œ, ë³´í—˜ê°€ì…, ë³´í—˜ìƒí’ˆ, ë³´í—˜ì•½ê´€, ë³´í—˜ë³´ì¥, ë³´í—˜í˜œíƒ
- ë³´í—˜ê¸ˆ, ë³´í—˜ì§€ê¸‰, ë³´í—˜ë°°ìƒ, ë³´í—˜ë©´ì±…, ë³´í—˜ì œì™¸, ë³´í—˜ì¡°ê±´, ë³´í—˜ê¸°ê°„, ë³´í—˜ë²”ìœ„, ë³´í—˜í•œë„
- í•´ì™¸ì—¬í–‰, í•´ì™¸ì¶œì¥, í•´ì™¸ê´€ê´‘, í•´ì™¸ë°©ë¬¸, í•´ì™¸ì²´ë¥˜, ì—¬í–‰, ì¶œì¥, ê´€ê´‘, ë°©ë¬¸, ì²´ë¥˜
- ì‚¼ì„±í™”ì¬, ì¹´ì¹´ì˜¤í˜ì´, í˜„ëŒ€í•´ìƒ, DBì†í•´ë³´í—˜, KBì†í•´ë³´í—˜ ë“± ë³´í—˜ì‚¬
- íŠ¹ì•½, ì˜ë£Œë¹„, ì¹˜ë£Œë¹„, í•­ê³µê¸°ì§€ì—°, ìˆ˜í•˜ë¬¼ì§€ì—°, ê°œì¸ë°°ìƒ, ì—¬í–‰ì¤‘ë‹¨, ê¸´ê¸‰ì˜ë£Œ ë“±
- ë³´ì¥ë‚´ìš©, ê°€ì…ì¡°ê±´, í•´ì§€, ê°±ì‹ , ë³´í—˜ê¸ˆì²­êµ¬ ë“±

ë§Œì•½ ì—¬í–‰ì ë³´í—˜ ë„ë©”ì¸ê³¼ ê´€ë ¨ë˜ì§€ ì•Šì€ ì§ˆë¬¸ì´ë¼ë©´:
- is_domain_related: false
- intent: "qa" (ì¼ë°˜ LLM ë‹µë³€)
- needs_web: false

ë§Œì•½ ì—¬í–‰ì ë³´í—˜ ë„ë©”ì¸ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì´ë¼ë©´:
- is_domain_related: true
- ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ intentë¥¼ ì„ íƒí•˜ì„¸ìš”:
  * "qa": ì¼ë°˜ì ì¸ ì§ˆë¬¸-ë‹µë³€ (ë³´ì¥ ë‚´ìš©, ê°€ì… ì¡°ê±´, ë³´í—˜ë£Œ ë“±)
  * "summary": ë¬¸ì„œ ìš”ì•½ (ì•½ê´€ ìš”ì•½, ìƒí’ˆ ì •ë¦¬ ë“±)
  * "compare": ë¹„êµ ë¶„ì„ (ë³´í—˜ ìƒí’ˆ ê°„ ë¹„êµ, ì°¨ì´ì  ë¶„ì„ ë“±)
  * "recommend": ì¶”ì²œ ë° ê¶Œì¥ (íŠ¹ì•½ ì¶”ì²œ, ì—¬í–‰ì§€ë³„ ë³´í—˜ ì¶”ì²œ ë“±)

- ë‹¤ìŒ ì¡°ê±´ì„ í™•ì¸í•˜ì—¬ needs_webì„ ê²°ì •í•˜ì„¸ìš”:
  * ìµœì‹  ë‰´ìŠ¤ë‚˜ ì‹¤ì‹œê°„ ì •ë³´ê°€ í•„ìš”í•œê°€?
  * íŠ¹ì • ë‚ ì§œë‚˜ ì§€ì—­ì˜ í˜„ì¬ ìƒí™©ì´ í•„ìš”í•œê°€?
  * ì—¬í–‰ì§€ì˜ í˜„ì¬ ì•ˆì „ ìƒí™©ì´ë‚˜ ê·œì œê°€ í•„ìš”í•œê°€?
  * ê°€ê²© ë¹„êµê°€ í•„ìš”í•œê°€?
  * ë¦¬ì›Œë“œ ì •ë³´ê°€ í•„ìš”í•œê°€?
"""

    try:
        logger.debug("LLMì„ ì‚¬ìš©í•œ ì˜ë„ ë¶„ë¥˜ ì‹œì‘ (structured output)")
        llm = get_planner_llm()
        
        # structured output ì‚¬ìš©
        structured_llm = llm.with_structured_output(PlannerResponse)
        response = structured_llm.generate_content(prompt)
        
        logger.debug(f"Structured LLM ì‘ë‹µ: {response}")
        
        # ìœ íš¨ì„± ê²€ì¦
        is_domain_related = response.is_domain_related
        if not isinstance(is_domain_related, bool):
            is_domain_related = _is_travel_insurance_domain(question)
            logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ is_domain_related: {is_domain_related}, íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì¬íŒë‹¨")
            
        intent = response.intent
        if intent not in INTENTS:
            logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ ì˜ë„: {intent}, ê¸°ë³¸ê°’ 'qa' ì‚¬ìš©")
            intent = "qa"
            
        needs_web = response.needs_web
        if not isinstance(needs_web, bool):
            needs_web = _determine_web_search_need(question, intent)
            logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ needs_web: {needs_web}, íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì¬íŒë‹¨")
            
        return {
            "is_domain_related": is_domain_related,
            "intent": intent,
            "needs_web": needs_web,
            "reasoning": response.reasoning
        }
        
    except Exception as e:
        logger.error(f"LLM ì˜ë„ ë¶„ë¥˜ ì‹¤íŒ¨, fallback ì‚¬ìš©: {str(e)}")
        return _fallback_classify(question)

def _fallback_classify(question: str) -> Dict[str, Any]:
    """
    LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•˜ëŠ” ê°€ì¤‘ì¹˜ ê¸°ë°˜ í–¥ìƒëœ fallback ë¶„ë¥˜ê¸°
    """
    ql = question.lower()
    
    # ê° intentë³„ ê°€ì¤‘ì¹˜ ì ìˆ˜ ê³„ì‚°
    intent_scores = {
        "summary": 0,
        "compare": 0, 
        "recommend": 0,
        "qa": 0
    }
    
    # Summary í‚¤ì›Œë“œ (ê°€ì¤‘ì¹˜: ë†’ìŒ) - ëª…ì‹œì  ìš”ì•½ ìš”ì²­ë§Œ
    summary_keywords = {
        "ìš”ì•½": 10, "ì •ë¦¬": 8, "summary": 10, "ì•½ê´€ ìš”ì•½": 12, 
        "ìƒí’ˆ ìš”ì•½": 12, "í•µì‹¬ ë‚´ìš©": 9, "ê°„ë‹¨íˆ": 6, "ì¤„ì—¬ì„œ": 7,
        "í•œëˆˆì—": 8, "ê°œìš”": 9, "ìš”ì ": 8, "ì´ì •ë¦¬": 10,
        "ìš”ì•½í•´ì£¼ì„¸ìš”": 12, "ì •ë¦¬í•´ì£¼ì„¸ìš”": 10, "ê°„ë‹¨íˆ ì„¤ëª…": 8  # ëª…ì‹œì  ìš”ì•½ ìš”ì²­
    }
    for keyword, weight in summary_keywords.items():
        if keyword in question:
            intent_scores["summary"] += weight
    
    # Compare í‚¤ì›Œë“œ (ê°€ì¤‘ì¹˜: ë†’ìŒ)
    compare_keywords = {
        "ë¹„êµ": 10, "ì°¨ì´": 9, "ë‹¤ë¥¸ ì ": 10, "compare": 10, 
        "vs": 8, "ëŒ€ë¹„": 8, "êµ¬ë¶„": 7, "ì–´ë–¤ ì°¨ì´": 12,
        "ì°¨ì´ì ": 10, "ë¹„êµí•´": 9, "ëŒ€ì¡°": 7, "ìƒì´": 6,
        "ë‹¤ë¥´ë‹¤": 8, "êµ¬ë³„": 7, "êµ¬ë¶„í•˜ë‹¤": 7
    }
    for keyword, weight in compare_keywords.items():
        if keyword in question:
            intent_scores["compare"] += weight
    
    # Recommend í‚¤ì›Œë“œ (ê°€ì¤‘ì¹˜: ë†’ìŒ)
    recommend_keywords = {
        "ì¶”ì²œ": 10, "íŠ¹ì•½": 9, "ê¶Œì¥": 9, "recommend": 10,
        "ì–´ë–¤": 7, "ì„ íƒ": 8, "ê°€ì¥ ì¢‹ì€": 11, "ìµœê³ ": 8,
        "ì¶”ì²œí•´": 9, "ì¶”ì²œí•´ì£¼": 9, "ì–´ë–¤ ê²Œ": 8, "ì–´ë–¤ ê²ƒì´": 8,
        "ì„ íƒí•´ì•¼": 9, "ê³ ë¥´ë‹¤": 7, "ê²°ì •": 6, "ì¶”ì²œë°›": 9,
        "ë„ì›€": 6, "ì¡°ì–¸": 7, "ê°€ì´ë“œ": 6, "ì–´ë–¤ ê±¸": 8,
        "ê°€ì¥ ì¢‹ì„ê¹Œ": 12, "ì–´ë–¤ ê²ƒì´ ì¢‹ì„ê¹Œ": 12, "ì–´ë–¤ ê²Œ ì¢‹ì„ê¹Œ": 12,
        "ì–´ë–¤ ë³´í—˜ì´": 15, "ì–´ë–¤ ìƒí’ˆì´": 15, "ì–´ë–¤ ê²ƒì´ ì¢‹ì„ê¹Œìš”": 15,  # ì¶”ê°€ recommend íŒ¨í„´
        "ê°€ì¥ ì¢‹ì„ê¹Œìš”": 15, "ì–´ë–¤ ê²Œ ì¢‹ì„ê¹Œìš”": 15
    }
    for keyword, weight in recommend_keywords.items():
        if keyword in question:
            intent_scores["recommend"] += weight
    
    # QA í‚¤ì›Œë“œ (ê°€ì¤‘ì¹˜: ì¤‘ê°„)
    qa_keywords = {
        "ë¬´ì—‡": 6, "ì–´ë–»ê²Œ": 6, "ì–¸ì œ": 6, "ì–´ë””ì„œ": 6, "ì™œ": 6,
        "ì–¼ë§ˆ": 6, "ëª‡": 6, "ì–´ëŠ": 6, "ë¬´ìŠ¨": 6, "ì–´ë–¤": 5,
        "ë³´ì¥": 8, "ê°€ì…": 7, "ë³´í—˜ë£Œ": 8, "ì¡°ê±´": 7, "ë‚´ìš©": 6,
        "í˜œíƒ": 7, "ì§€ê¸‰": 7, "ë°°ìƒ": 7, "ë©´ì±…": 6, "ì œì™¸": 6,
        "í¬í•¨": 6, "ì ìš©": 6, "ê¸°ê°„": 6, "ë²”ìœ„": 6, "í•œë„": 7,
        "ì¡°í•­": 6, "ê·œì •": 6, "ì •ì±…": 6, "ì•½ê´€": 7, "ë³´ìƒ": 5,  # ë³´ìƒ ê°€ì¤‘ì¹˜ ê°ì†Œ
        "ë­ì•¼": 6, "ë˜ë‚˜ìš”": 6, "ì¸ê°€ìš”": 6, "ì¸ì§€": 6  # ì¶”ê°€ QA ì§ˆë¬¸ì–´
    }
    for keyword, weight in qa_keywords.items():
        if keyword in question:
            intent_scores["qa"] += weight
    
    # ë¬¸ë§¥ ë¶„ì„ì„ í†µí•œ ì¶”ê°€ ì ìˆ˜
    context_boost = _analyze_question_context(question)
    for intent, boost in context_boost.items():
        intent_scores[intent] += boost
    
    # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ intent ì„ íƒ
    intent = max(intent_scores, key=intent_scores.get)
    
    # ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ê¸°ë³¸ê°’ì¸ qaë¡œ ì„¤ì •
    if intent_scores[intent] < 5:
        intent = "qa"
    
    # ì›¹ ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨ (ê°œì„ ëœ ë¡œì§)
    needs_web = _determine_web_search_need(question, intent)
    
    # ë¶„ë¥˜ ê²°ê³¼ ë¡œê¹… (ë””ë²„ê¹…ìš©)
    print(f"ğŸ” Fallback ë¶„ë¥˜ ê²°ê³¼: {intent} (ì ìˆ˜: {intent_scores[intent]}, ì›¹ê²€ìƒ‰: {needs_web})")
    
    # ë„ë©”ì¸ ê´€ë ¨ì„± ê²€ì‚¬
    is_domain_related = _is_travel_insurance_domain(question)
    
    return {
        "is_domain_related": is_domain_related,
        "intent": intent,
        "needs_web": needs_web,
        "reasoning": f"Enhanced fallback: {intent} (score: {intent_scores[intent]}, web: {needs_web}, domain: {is_domain_related})"
    }

def _analyze_question_context(question: str) -> Dict[str, int]:
    """
    ì§ˆë¬¸ì˜ ë¬¸ë§¥ì„ ë¶„ì„í•˜ì—¬ intentë³„ ì¶”ê°€ ì ìˆ˜ë¥¼ ë¶€ì—¬
    """
    context_boost = {"summary": 0, "compare": 0, "recommend": 0, "qa": 0}
    
    # ì§ˆë¬¸ í˜•íƒœ ë¶„ì„
    if question.endswith("?"):
        context_boost["qa"] += 3
    
    # ë³µìˆ˜ ë¹„êµ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ compare ì ìˆ˜ ì¦ê°€
    compare_indicators = ["ì—¬ëŸ¬", "ëª‡ ê°œ", "ì—¬ëŸ¬ ê°œ", "ë‹¤ì–‘í•œ", "ê°ê°", "ëª¨ë“ "]
    if any(indicator in question for indicator in compare_indicators):
        context_boost["compare"] += 5
    
    # ìš”ì•½ ê´€ë ¨ ë¬¸ë§¥ í‚¤ì›Œë“œ (ëª…ì‹œì  ìš”ì•½ ìš”ì²­ë§Œ)
    summary_context = ["ì „ì²´", "ëª¨ë“ ", "ì¢…í•©", "í¬ê´„", "ì´", "ì „ë°˜"]
    if any(ctx in question for ctx in summary_context):
        context_boost["summary"] += 4
    
    # ì¶”ì²œ ê´€ë ¨ ë¬¸ë§¥ í‚¤ì›Œë“œ
    recommend_context = ["ë‚˜ì—ê²Œ", "ë‚´ê°€", "ì €ì—ê²Œ", "ì œê°€", "ì í•©í•œ", "ë§ëŠ”", "ì¢‹ì€"]
    if any(ctx in question for ctx in recommend_context):
        context_boost["recommend"] += 4
    
    # ë³´í—˜ ê´€ë ¨ ì „ë¬¸ ìš©ì–´ê°€ ë§ìœ¼ë©´ QA ì ìˆ˜ ì¦ê°€
    insurance_terms = ["ë³´í—˜ë£Œ", "ë³´ì¥", "ë©´ì±…", "ì§€ê¸‰", "ë°°ìƒ", "ê°€ì…", "í•´ì§€", "ê°±ì‹ "]
    term_count = sum(1 for term in insurance_terms if term in question)
    context_boost["qa"] += min(term_count * 2, 8)  # ìµœëŒ€ 8ì 
    
    # ë³´í—˜ ì¡°í•­/ê·œì • ê´€ë ¨ ì§ˆë¬¸ì€ ìë™ìœ¼ë¡œ compare intentë¡œ ë¶„ë¥˜
    # ë‹¨, "ìš”ì•½" í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ summary ìš°ì„ 
    clause_keywords = ["ì¡°í•­", "ê·œì •", "ì •ì±…", "ì•½ê´€", "ë³´ìƒ", "ë³´ìƒ ê·œì •"]
    summary_keywords = ["ìš”ì•½", "ì •ë¦¬", "ê°œìš”", "í•µì‹¬", "ì£¼ìš”"]
    
    # ì¡°í•­/ê·œì • í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê´€ë ¨ intent ì ìˆ˜ë¥¼ ë¶€ë“œëŸ½ê²Œ ê°€ì¤‘ì¹˜ ë¶€ì—¬ (ê°•ì œì„± ì™„í™”)
    if any(keyword in question for keyword in clause_keywords):
        # "ìš”ì•½" ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ summaryì— ë†’ì€ ê°€ì¤‘ì¹˜
        if any(summary_kw in question for summary_kw in summary_keywords):
            context_boost["summary"] += 8  # summary ìš°ì„ , ê¸°ì¡´ë³´ë‹¤ ë‚®ì€ ì ìˆ˜
        # "ì–´ë–»ê²Œ", "ë­ì•¼" ë“± ì§ˆë¬¸ì–´ê°€ ìˆìœ¼ë©´ qaì— ê°€ì¤‘ì¹˜
        elif any(q_word in question for q_word in ["ì–´ë–»ê²Œ", "ë­ì•¼", "ë¬´ì—‡", "ë¬´ìŠ¨", "ì–´ë–¤", "ë˜ë‚˜ìš”"]):
            context_boost["qa"] += 7  # ê¸°ì¡´ë³´ë‹¤ ë‚®ì€ ì ìˆ˜

    
    return context_boost

def _is_travel_insurance_domain(question: str) -> bool:
    """
    ì§ˆë¬¸ì´ ì—¬í–‰ì ë³´í—˜ ë„ë©”ì¸ê³¼ ê´€ë ¨ëœì§€ íŒë‹¨í•©ë‹ˆë‹¤.
    """
    ql = question.lower()
    
    # ì—¬í–‰ì ë³´í—˜ ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œ
    travel_insurance_keywords = [
        # ë³´í—˜ ê´€ë ¨
        "ì—¬í–‰ìë³´í—˜", "ì—¬í–‰ë³´í—˜", "í•´ì™¸ì—¬í–‰ë³´í—˜", "í•´ì™¸ë³´í—˜", "ì—¬í–‰ìë³´í—˜ë£Œ", "ì—¬í–‰ë³´í—˜ë£Œ",
        "ë³´í—˜ë£Œ", "ë³´í—˜ê°€ì…", "ë³´í—˜ìƒí’ˆ", "ë³´í—˜ì•½ê´€", "ë³´í—˜ë³´ì¥", "ë³´í—˜í˜œíƒ",
        "ë³´í—˜ê¸ˆ", "ë³´í—˜ì§€ê¸‰", "ë³´í—˜ë°°ìƒ", "ë³´í—˜ë©´ì±…", "ë³´í—˜ì œì™¸", "ë³´í—˜ì¡°ê±´",
        "ë³´í—˜ê¸°ê°„", "ë³´í—˜ë²”ìœ„", "ë³´í—˜í•œë„", "ë³´í—˜ì¡°í•­", "ë³´í—˜ê·œì •", "ë³´í—˜ì •ì±…",
        "ë³´í—˜ë³´ìƒ", "ë³´í—˜ê¸ˆì§€ê¸‰", "ë³´í—˜ê¸ˆë°°ìƒ", "ë³´í—˜ê¸ˆë©´ì±…", "ë³´í—˜ê¸ˆì œì™¸",
        
        # ì—¬í–‰ ê´€ë ¨
        "í•´ì™¸ì—¬í–‰", "í•´ì™¸ì¶œì¥", "í•´ì™¸ê´€ê´‘", "í•´ì™¸ë°©ë¬¸", "í•´ì™¸ì²´ë¥˜", "í•´ì™¸íœ´ê°€",
        "ì—¬í–‰", "ì¶œì¥", "ê´€ê´‘", "ë°©ë¬¸", "ì²´ë¥˜", "íœ´ê°€", "ì—¬í–‰ì§€", "ì—¬í–‰êµ­ê°€",
        "ì—¬í–‰ê¸°ê°„", "ì—¬í–‰ëª©ì ", "ì—¬í–‰ì¼ì •", "ì—¬í–‰ê³„íš", "ì—¬í–‰ì¤€ë¹„",
        
        # ë³´í—˜ì‚¬ ê´€ë ¨
        "ì‚¼ì„±í™”ì¬", "ì¹´ì¹´ì˜¤í˜ì´", "í˜„ëŒ€í•´ìƒ", "dbì†í•´ë³´í—˜", "kbì†í•´ë³´í—˜",
        "ì‚¼ì„±", "ì¹´ì¹´ì˜¤", "í˜„ëŒ€", "db", "kb", "ë™ë¶€í™”ì¬", "ë™ë¶€", "kbì†í•´",
        
        # íŠ¹ì•½ ê´€ë ¨
        "íŠ¹ì•½", "ì„ íƒíŠ¹ì•½", "ê¸°ë³¸íŠ¹ì•½", "ì¶”ê°€íŠ¹ì•½", "íŠ¹ë³„ì•½ê´€", "íŠ¹ë³„ì¡°í•­",
        "ì˜ë£Œë¹„", "ì¹˜ë£Œë¹„", "ë³‘ì›ë¹„", "ì˜ë£Œë³´ì¥", "ì¹˜ë£Œë³´ì¥", "ë³‘ì›ë³´ì¥",
        "í•­ê³µê¸°ì§€ì—°", "í•­ê³µê¸°ê²°í•­", "í•­ê³µê¸°ì·¨ì†Œ", "í•­ê³µê¸°ì§€ì—°ë³´ì¥", "í•­ê³µê¸°ê²°í•­ë³´ì¥",
        "ìˆ˜í•˜ë¬¼ì§€ì—°", "ìˆ˜í•˜ë¬¼ë¶„ì‹¤", "ìˆ˜í•˜ë¬¼ì†ìƒ", "ìˆ˜í•˜ë¬¼ë³´ì¥", "ìˆ˜í•˜ë¬¼ì§€ì—°ë³´ì¥",
        "ê°œì¸ë°°ìƒ", "ê°œì¸ë°°ìƒì±…ì„", "ë°°ìƒì±…ì„", "ë°°ìƒë³´ì¥", "ì±…ì„ë³´ì¥",
        "ì—¬í–‰ì¤‘ë‹¨", "ì—¬í–‰ì·¨ì†Œ", "ì—¬í–‰ì§€ì—°", "ì—¬í–‰ì¤‘ë‹¨ë³´ì¥", "ì—¬í–‰ì·¨ì†Œë³´ì¥",
        "ê¸´ê¸‰ì˜ë£Œ", "ê¸´ê¸‰ì†¡í™˜", "ê¸´ê¸‰ì˜ë£Œì†¡í™˜", "ê¸´ê¸‰ì˜ë£Œë³´ì¥", "ê¸´ê¸‰ì†¡í™˜ë³´ì¥",
        
        # ë³´ì¥ ë‚´ìš© ê´€ë ¨
        "ë³´ì¥ë‚´ìš©", "ë³´ì¥í•­ëª©", "ë³´ì¥ë²”ìœ„", "ë³´ì¥í•œë„", "ë³´ì¥ì¡°ê±´", "ë³´ì¥ê¸°ê°„",
        "ì§€ê¸‰ì¡°ê±´", "ì§€ê¸‰í•œë„", "ì§€ê¸‰ë²”ìœ„", "ì§€ê¸‰ê¸°ì¤€", "ì§€ê¸‰ì ˆì°¨",
        "ë©´ì±…ì¡°í•­", "ë©´ì±…ì‚¬í•­", "ë©´ì±…ê¸°ê°„", "ë©´ì±…ë²”ìœ„", "ë©´ì±…ì¡°ê±´",
        "ì œì™¸ì¡°í•­", "ì œì™¸ì‚¬í•­", "ì œì™¸ê¸°ê°„", "ì œì™¸ë²”ìœ„", "ì œì™¸ì¡°ê±´",
        
        # ê°€ì… ê´€ë ¨
        "ê°€ì…ì¡°ê±´", "ê°€ì…ìê²©", "ê°€ì…ì ˆì°¨", "ê°€ì…ë°©ë²•", "ê°€ì…ì‹ ì²­", "ê°€ì…ì„œë¥˜",
        "ê°€ì…ë¹„ìš©", "ê°€ì…ìš”ê¸ˆ", "ê°€ì…ìˆ˜ìˆ˜ë£Œ", "ê°€ì…ë³´í—˜ë£Œ", "ê°€ì…ê¸ˆì•¡",
        "ê°€ì…ê¸°ê°„", "ê°€ì…ì¼", "ê°€ì…ì‹œê¸°", "ê°€ì…ì‹œì ", "ê°€ì…ì‹œì ",
        
        # í•´ì§€/ê°±ì‹  ê´€ë ¨
        "í•´ì§€", "í•´ì§€ì¡°ê±´", "í•´ì§€ì ˆì°¨", "í•´ì§€ë°©ë²•", "í•´ì§€ì‹œê¸°", "í•´ì§€ì‹œì ",
        "ê°±ì‹ ", "ê°±ì‹ ì¡°ê±´", "ê°±ì‹ ì ˆì°¨", "ê°±ì‹ ë°©ë²•", "ê°±ì‹ ì‹œê¸°", "ê°±ì‹ ì‹œì ",
        "ìë™ê°±ì‹ ", "ìˆ˜ë™ê°±ì‹ ", "ê°±ì‹ ë³´í—˜ë£Œ", "ê°±ì‹ ê¸ˆì•¡", "ê°±ì‹ ê¸°ê°„",
        
        # ë³´í—˜ê¸ˆ ì²­êµ¬ ê´€ë ¨
        "ë³´í—˜ê¸ˆì²­êµ¬", "ë³´í—˜ê¸ˆì‹ ì²­", "ë³´í—˜ê¸ˆì§€ê¸‰", "ë³´í—˜ê¸ˆë°°ìƒ", "ë³´í—˜ê¸ˆì²˜ë¦¬",
        "ì²­êµ¬ì ˆì°¨", "ì²­êµ¬ë°©ë²•", "ì²­êµ¬ì„œë¥˜", "ì²­êµ¬ì¡°ê±´", "ì²­êµ¬ê¸°ê°„",
        "ì§€ê¸‰ì ˆì°¨", "ì§€ê¸‰ë°©ë²•", "ì§€ê¸‰ì„œë¥˜", "ì§€ê¸‰ì¡°ê±´", "ì§€ê¸‰ê¸°ê°„",
        
        # ë¹„êµ/ì¶”ì²œ ê´€ë ¨
        "ë³´í—˜ë¹„êµ", "ë³´í—˜ìƒí’ˆë¹„êµ", "ë³´í—˜ë£Œë¹„êµ", "ë³´í—˜ë³´ì¥ë¹„êµ", "ë³´í—˜í˜œíƒë¹„êµ",
        "ë³´í—˜ì¶”ì²œ", "ë³´í—˜ìƒí’ˆì¶”ì²œ", "ë³´í—˜ì„ íƒ", "ë³´í—˜ê°€ì´ë“œ", "ë³´í—˜ìƒë‹´",
        "ì–´ë–¤ë³´í—˜", "ì–´ë–¤ìƒí’ˆ", "ì–´ë–¤ë³´í—˜ì´", "ì–´ë–¤ìƒí’ˆì´", "ì–´ë–¤ê²ƒì´",
        
        # ìš”ì•½ ê´€ë ¨
        "ë³´í—˜ì•½ê´€", "ë³´í—˜ì¡°í•­", "ë³´í—˜ê·œì •", "ë³´í—˜ì •ì±…", "ë³´í—˜ë‚´ìš©",
        "ì•½ê´€ìš”ì•½", "ì¡°í•­ìš”ì•½", "ê·œì •ìš”ì•½", "ì •ì±…ìš”ì•½", "ë‚´ìš©ìš”ì•½",
        "ë³´í—˜ì •ë¦¬", "ë³´í—˜ê°œìš”", "ë³´í—˜í•µì‹¬", "ë³´í—˜ì£¼ìš”", "ë³´í—˜ì´ì •ë¦¬"
    ]
    
    # ì—¬í–‰ì ë³´í—˜ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
    domain_score = 0
    for keyword in travel_insurance_keywords:
        if keyword in ql:
            domain_score += 1
    
    # ì—¬í–‰ì ë³´í—˜ ë„ë©”ì¸ ê´€ë ¨ í‚¤ì›Œë“œê°€ 1ê°œ ì´ìƒ ìˆìœ¼ë©´ ë„ë©”ì¸ ê´€ë ¨ìœ¼ë¡œ íŒë‹¨
    is_domain_related = domain_score > 0
    
    # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸
    logger.debug(f"ë„ë©”ì¸ ê´€ë ¨ì„± ì ìˆ˜: {domain_score}ì , ë„ë©”ì¸ ê´€ë ¨: {is_domain_related}")
    
    return is_domain_related

def _determine_web_search_need(question: str, intent: str) -> bool:
    """
    ì›¹ ê²€ìƒ‰ í•„ìš”ì„±ì„ ì •êµí•˜ê²Œ íŒë‹¨
    """
    ql = question.lower()
    
    # ë‚ ì§œ íŒ¨í„´ (í™•ì¥)
    date_patterns = [
        # ì—°ë„ íŒ¨í„´
        r"\d{4}ë…„", r"\d{4}-\d{2}", r"\d{4}/\d{2}", r"\d{4}\.\d{2}",
        r"\d{4}ë…„\s*\d{1,2}ì›”", r"\d{4}-\d{2}-\d{2}", r"\d{4}/\d{2}/\d{2}",
        
        # ì›” íŒ¨í„´
        r"\d{1,2}ì›”", r"\d{1,2}ì›”\s*\d{1,2}ì¼", r"\d{1,2}ì›”\s*\d{1,2}ì¼",
        r"1ì›”", r"2ì›”", r"3ì›”", r"4ì›”", r"5ì›”", r"6ì›”",
        r"7ì›”", r"8ì›”", r"9ì›”", r"10ì›”", r"11ì›”", r"12ì›”",
        r"ì¼ì›”", r"ì´ì›”", r"ì‚¼ì›”", r"ì‚¬ì›”", r"ì˜¤ì›”", r"ìœ ì›”",
        r"ì¹ ì›”", r"íŒ”ì›”", r"êµ¬ì›”", r"ì‹œì›”", r"ì‹­ì¼ì›”", r"ì‹­ì´ì›”",
        
        # ê³„ì ˆ íŒ¨í„´
        r"ë´„", r"ì—¬ë¦„", r"ê°€ì„", r"ê²¨ìš¸", r"ë´„ì² ", r"ì—¬ë¦„ì² ", r"ê°€ì„ì² ", r"ê²¨ìš¸ì² ",
        r"ë´„ì—¬í–‰", r"ì—¬ë¦„ì—¬í–‰", r"ê°€ì„ì—¬í–‰", r"ê²¨ìš¸ì—¬í–‰",
        r"ë´„íœ´ê°€", r"ì—¬ë¦„íœ´ê°€", r"ê°€ì„íœ´ê°€", r"ê²¨ìš¸íœ´ê°€",
        
        # ì£¼ ë‹¨ìœ„ íŒ¨í„´
        r"ë‹¤ìŒì£¼", r"ì´ë²ˆ ì£¼", r"ì´ë²ˆì£¼", r"ë‹¤ìŒ ì£¼", r"ì´ë²ˆì£¼ë§", r"ë‹¤ìŒì£¼ë§",
        r"ì£¼ë§", r"ì£¼ì¤‘", r"í‰ì¼", r"íœ´ì¼", r"ê³µíœ´ì¼",
        r"ì¼ì£¼ì¼", r"2ì£¼ì¼", r"3ì£¼ì¼", r"í•œ ì£¼", r"ë‘ ì£¼", r"ì„¸ ì£¼",
        r"ì¼ì£¼ì¼ í›„", r"2ì£¼ì¼ í›„", r"3ì£¼ì¼ í›„", r"í•œ ì£¼ í›„", r"ë‘ ì£¼ í›„",
        r"ì¼ì£¼ì¼ ì´ë‚´", r"2ì£¼ì¼ ì´ë‚´", r"3ì£¼ì¼ ì´ë‚´", r"í•œ ì£¼ ì´ë‚´", r"ë‘ ì£¼ ì´ë‚´",
        
        # ì¼ ë‹¨ìœ„ íŒ¨í„´
        r"ë‚´ì¼", r"ì˜¤ëŠ˜", r"ëª¨ë ˆ", r"ê¸€í”¼", r"ì–´ì œ", r"ê·¸ì œ",
        r"ì˜¤ëŠ˜ë¶€í„°", r"ë‚´ì¼ë¶€í„°", r"ëª¨ë ˆë¶€í„°", r"ì˜¤ëŠ˜ë¶€í„°\s*\d+ì¼",
        r"ë‚´ì¼ë¶€í„°\s*\d+ì¼", r"ëª¨ë ˆë¶€í„°\s*\d+ì¼",
        r"\d+ì¼ í›„", r"\d+ì¼ ë’¤", r"\d+ì¼ ë’¤ì—", r"\d+ì¼ í›„ì—",
        r"ë©°ì¹  í›„", r"ë©°ì¹  ë’¤", r"ë©°ì¹  ë’¤ì—", r"ë©°ì¹  í›„ì—",
        r"í•˜ë£¨", r"ì´í‹€", r"ì‚¬í˜", r"ë‚˜í˜", r"ë‹·ìƒˆ", r"ì—¿ìƒˆ", r"ì´ë ˆ",
        r"í•˜ë£¨ í›„", r"ì´í‹€ í›„", r"ì‚¬í˜ í›„", r"ë‚˜í˜ í›„", r"ë‹·ìƒˆ í›„",
        
        # ì›” ë‹¨ìœ„ íŒ¨í„´
        r"ë‹¤ìŒ ë‹¬", r"ì´ë²ˆ ë‹¬", r"ì´ë²ˆë‹¬", r"ë‹¤ìŒë‹¬", r"ë‹¤ìŒ ë‹¬", r"ì´ë²ˆ ë‹¬",
        r"í•œ ë‹¬", r"ë‘ ë‹¬", r"ì„¸ ë‹¬", r"1ê°œì›”", r"2ê°œì›”", r"3ê°œì›”",
        r"í•œ ë‹¬ í›„", r"ë‘ ë‹¬ í›„", r"ì„¸ ë‹¬ í›„", r"1ê°œì›” í›„", r"2ê°œì›” í›„",
        r"í•œ ë‹¬ ì´ë‚´", r"ë‘ ë‹¬ ì´ë‚´", r"ì„¸ ë‹¬ ì´ë‚´", r"1ê°œì›” ì´ë‚´", r"2ê°œì›” ì´ë‚´",
        
        # ì—°ë„ íŒ¨í„´
        r"ë‚´ë…„", r"ì˜¬í•´", r"ì‘ë…„", r"ë‚´í›„ë…„", r"ì¬ì‘ë…„",
        r"2024ë…„", r"2025ë…„", r"2026ë…„", r"2027ë…„", r"2028ë…„",
        r"ë‚´ë…„ ì—¬ë¦„", r"ë‚´ë…„ ê²¨ìš¸", r"ì˜¬í•´ ì—¬ë¦„", r"ì˜¬í•´ ê²¨ìš¸",
        r"ë‚´ë…„ ë´„", r"ë‚´ë…„ ê°€ì„", r"ì˜¬í•´ ë´„", r"ì˜¬í•´ ê°€ì„",
        
        # ì‹œê°„ ê´€ë ¨ íŒ¨í„´
        r"í˜„ì¬", r"ì§€ê¸ˆ", r"ìš”ì¦˜", r"ìµœê·¼", r"ìµœì‹ ", r"ìš”ìƒˆ", r"ìš”ì¦ˆìŒ",
        r"ìµœê·¼ì—", r"ìš”ì¦˜ì—", r"ì§€ê¸ˆê¹Œì§€", r"í˜„ì¬ê¹Œì§€", r"ìš”ì¦˜ê¹Œì§€",
        r"ìµœê·¼ ëª‡", r"ìš”ì¦˜ ëª‡", r"ì§€ê¸ˆ ëª‡", r"í˜„ì¬ ëª‡",
        r"ìµœê·¼ ëª‡ì¼", r"ìš”ì¦˜ ëª‡ì¼", r"ì§€ê¸ˆ ëª‡ì¼", r"í˜„ì¬ ëª‡ì¼",
        r"ìµœê·¼ ëª‡ì£¼", r"ìš”ì¦˜ ëª‡ì£¼", r"ì§€ê¸ˆ ëª‡ì£¼", r"í˜„ì¬ ëª‡ì£¼",
        r"ìµœê·¼ ëª‡ê°œì›”", r"ìš”ì¦˜ ëª‡ê°œì›”", r"ì§€ê¸ˆ ëª‡ê°œì›”", r"í˜„ì¬ ëª‡ê°œì›”",
        
        # íŠ¹ë³„í•œ ë‚ ì§œ íŒ¨í„´
        r"ì„¤ë‚ ", r"ì¶”ì„", r"ì–´ë¦°ì´ë‚ ", r"ì–´ë²„ì´ë‚ ", r"ìŠ¤ìŠ¹ì˜ë‚ ",
        r"í˜„ì¶©ì¼", r"ê´‘ë³µì ˆ", r"ê°œì²œì ˆ", r"í•œê¸€ë‚ ", r"í¬ë¦¬ìŠ¤ë§ˆìŠ¤",
        r"ì‹ ì •", r"êµ¬ì •", r"ë¶€ì²˜ë‹˜ì˜¤ì‹ ë‚ ", r"ì–´ë¦°ì´ë‚ ", r"ì–´ë²„ì´ë‚ ",
        r"ì„¤ë‚  ì—°íœ´", r"ì¶”ì„ ì—°íœ´", r"ì–´ë¦°ì´ë‚  ì—°íœ´", r"í˜„ì¶©ì¼ ì—°íœ´",
        r"ê´‘ë³µì ˆ ì—°íœ´", r"ê°œì²œì ˆ ì—°íœ´", r"í•œê¸€ë‚  ì—°íœ´", r"í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì—°íœ´",
        
        # íœ´ê°€/ì—¬í–‰ ê´€ë ¨ íŒ¨í„´
        r"íœ´ê°€", r"ì—¬í–‰", r"ì¶œì¥", r"ê´€ê´‘", r"ë°©ë¬¸", r"ì²´ë¥˜",
        r"íœ´ê°€ì² ", r"ì—¬í–‰ì² ", r"ì¶œì¥ì² ", r"ê´€ê´‘ì² ", r"ë°©ë¬¸ì² ",
        r"íœ´ê°€ ê¸°ê°„", r"ì—¬í–‰ ê¸°ê°„", r"ì¶œì¥ ê¸°ê°„", r"ê´€ê´‘ ê¸°ê°„", r"ë°©ë¬¸ ê¸°ê°„",
        r"íœ´ê°€ ë•Œ", r"ì—¬í–‰ ë•Œ", r"ì¶œì¥ ë•Œ", r"ê´€ê´‘ ë•Œ", r"ë°©ë¬¸ ë•Œ",
        r"íœ´ê°€ ì¤‘", r"ì—¬í–‰ ì¤‘", r"ì¶œì¥ ì¤‘", r"ê´€ê´‘ ì¤‘", r"ë°©ë¬¸ ì¤‘",
        
        # ê¸°ê°„ í‘œí˜„ íŒ¨í„´
        r"ê¸°ê°„", r"ë™ì•ˆ", r"ì‚¬ì´", r"ì¤‘ì—", r"ë•Œ", r"ì¤‘",
        r"ë¶€í„°", r"ê¹Œì§€", r"~", r"-", r"ì—ì„œ", r"ë¡œ",
        r"ì´ë‚´", r"ì•ˆì—", r"ë‚´ì—", r"í›„", r"ë’¤", r"ë’¤ì—", r"í›„ì—",
        r"ì „ì—", r"ì•ì—", r"ì•ì„œ", r"ì´ì „", r"ì´í›„", r"ì´í›„ì—",
        
        # ìˆ«ì + ë‹¨ìœ„ íŒ¨í„´
        r"\d+ì¼", r"\d+ì£¼", r"\d+ê°œì›”", r"\d+ë…„",
        r"\d+ì¼ê°„", r"\d+ì£¼ê°„", r"\d+ê°œì›”ê°„", r"\d+ë…„ê°„",
        r"\d+ì¼ ë™ì•ˆ", r"\d+ì£¼ ë™ì•ˆ", r"\d+ê°œì›” ë™ì•ˆ", r"\d+ë…„ ë™ì•ˆ",
        r"\d+ì¼ì§¸", r"\d+ì£¼ì§¸", r"\d+ê°œì›”ì§¸", r"\d+ë…„ì§¸",
        
        # ìƒëŒ€ì  ì‹œê°„ í‘œí˜„
        r"ê³§", r"ê°€ê¹Œìš´", r"ê°€ê¹Œìš´ ì‹œì¼", r"ê°€ê¹Œìš´ ì¥ë˜", r"ê°€ê¹Œìš´ ë¯¸ë˜",
        r"ì¡°ë§Œê°„", r"ì–¼ë§ˆ ì•ˆ", r"ì–¼ë§ˆ ì•ˆì—", r"ì–¼ë§ˆ ì•ˆ ë˜ì–´", r"ì–¼ë§ˆ ì•ˆ ë¼ì„œ",
        r"ê¸ˆë°©", r"ë°”ë¡œ", r"ì¦‰ì‹œ", r"ë‹¹ì¥", r"ì§€ê¸ˆ ë‹¹ì¥", r"ì§€ê¸ˆ ë°”ë¡œ",
        r"ì–¸ì œë“ ", r"ì–¸ì œë“ ì§€", r"ì–¸ì œë‚˜", r"í•­ìƒ", r"ê³„ì†", r"ì§€ì†ì ìœ¼ë¡œ"
    ]
    has_date = any(re.search(pattern, question) for pattern in date_patterns)
    
    # ì§€ì—­ í‚¤ì›Œë“œ (í•µì‹¬ ë„ì‹œë§Œ ì„ ë³„)
    key_cities = [
        # ì£¼ìš” ì—¬í–‰ì§€
        "ë„ì¿„", "ì˜¤ì‚¬ì¹´", "íŒŒë¦¬", "ëŸ°ë˜", "ë‰´ìš•", "ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤",
        "ë°©ì½•", "ì‹±ê°€í¬ë¥´", "í™ì½©", "ì‹œë“œë‹ˆ", "ë©œë²„ë¥¸", "ë‘ë°”ì´",
        "ë² ë¥¼ë¦°", "ë¡œë§ˆ", "ë§ˆë“œë¦¬ë“œ", "ì•”ìŠ¤í…Œë¥´ë‹´", "ì·¨ë¦¬íˆ",
        "ìƒí•˜ì´", "ë² ì´ì§•", "í˜¸ì¹˜ë¯¼", "í•˜ë…¸ì´", "ìì¹´ë¥´íƒ€", "ë°œë¦¬",
        "ë§ˆë‹ë¼", "ì„¸ë¶€", "í”„ë†ˆíœ", "ì‹œì— ë¦½", "ë¹„ì—”í‹°ì•ˆ", "ì–‘ê³¤",
        "ë­„ë°”ì´", "ë¸ë¦¬", "ë°©ê°ˆë¡œë¥´", "ì•„ë¶€ë‹¤ë¹„", "ë„í•˜", "ë¦¬ì•¼ë“œ",
        "ë¸Œë¦¬ì¦ˆë²ˆ", "í¼ìŠ¤", "ì˜¤í´ëœë“œ", "í† ë¡ í† ", "ë°´ì¿ ë²„", "ëª¬íŠ¸ë¦¬ì˜¬",
        "ìƒíŒŒìš¸ë£¨", "ë¦¬ìš°ë°ìë„¤ì´ë£¨", "ë¶€ì—ë…¸ìŠ¤ì•„ì´ë ˆìŠ¤", "ì‚°í‹°ì•„ê³ ",
        "ì¼€ì´í”„íƒ€ìš´", "ìš”í•˜ë„¤ìŠ¤ë²„ê·¸", "ëª¨ìŠ¤í¬ë°”", "í‚¤ì˜ˆí”„", "ë°”ë¥´ìƒ¤ë°”",
        
        # êµ­ê°€ëª…
        "ë¯¸êµ­", "ì¼ë³¸", "ì¤‘êµ­", "íƒœêµ­", "ë² íŠ¸ë‚¨", "ì‹±ê°€í¬ë¥´", "ë§ë ˆì´ì‹œì•„",
        "ì¸ë„ë„¤ì‹œì•„", "í•„ë¦¬í•€", "ì¸ë„", "í˜¸ì£¼", "ë‰´ì§ˆëœë“œ", "ìºë‚˜ë‹¤",
        "ì˜êµ­", "í”„ë‘ìŠ¤", "ë…ì¼", "ì´íƒˆë¦¬ì•„", "ìŠ¤í˜ì¸", "ë„¤ëœë€ë“œ",
        "ìŠ¤ìœ„ìŠ¤", "ì˜¤ìŠ¤íŠ¸ë¦¬ì•„", "ë²¨ê¸°ì—", "ë´ë§ˆí¬", "ìŠ¤ì›¨ë´", "ë…¸ë¥´ì›¨ì´",
        "í•€ë€ë“œ", "ëŸ¬ì‹œì•„", "í„°í‚¤", "ê·¸ë¦¬ìŠ¤", "í¬ë¥´íˆ¬ê°ˆ", "ì•„ì¼ëœë“œ",
        "í´ë€ë“œ", "ì²´ì½”", "í—ê°€ë¦¬", "ë£¨ë§ˆë‹ˆì•„", "ë¶ˆê°€ë¦¬ì•„", "í¬ë¡œì•„í‹°ì•„",
        "ì„¸ë¥´ë¹„ì•„", "ìš°í¬ë¼ì´ë‚˜", "ë²¨ë¼ë£¨ìŠ¤", "ë¦¬íˆ¬ì•„ë‹ˆì•„", "ë¼íŠ¸ë¹„ì•„",
        "ì—ìŠ¤í† ë‹ˆì•„", "ìœ ëŸ½", "ì•„ì‹œì•„", "ì•„ë©”ë¦¬ì¹´", "ë¶ë¯¸", "ë‚¨ë¯¸",
        "ì˜¤ì„¸ì•„ë‹ˆì•„", "ì•„í”„ë¦¬ì¹´", "ì¤‘ë™", "ë™ë‚¨ì•„ì‹œì•„", "ë™ì•„ì‹œì•„"
    ]
    has_city = any(city in ql for city in key_cities)
    
    # ì‹¤ì‹œê°„ ì •ë³´ í‚¤ì›Œë“œ (í™•ì¥)
    live_keywords = [
        "ë‰´ìŠ¤", "í˜„ì§€", "ì‹¤ì‹œê°„", "ìµœì‹ ", "í˜„ì¬", "ì§€ê¸ˆ", "ìš”ì¦˜",
        "ìƒí™©", "ì •ë³´", "í˜„í™©", "ë™í–¥", "íŠ¸ë Œë“œ", "ë³€í™”", "ì—…ë°ì´íŠ¸",
        "ìµœê·¼", "ìƒˆë¡œìš´", "ë³€ê²½", "ìˆ˜ì •", "ë°œí‘œ", "ê³µì§€"
    ]
    has_live = any(keyword in question for keyword in live_keywords)
    
    # ì•ˆì „/ë³´ì•ˆ ê´€ë ¨ í‚¤ì›Œë“œ
    safety_keywords = [
        "ì•ˆì „", "ë³´ì•ˆ", "ìœ„í—˜", "ì£¼ì˜", "ê²½ê³ ", "ê¸ˆì§€", "ì œí•œ",
        "í…ŒëŸ¬", "ì‚¬ê³ ", "ì¬ë‚œ", "ì¬í•´", "ê°ì—¼", "ì§ˆë³‘", "ì „ì—¼ë³‘",
        "ì½”ë¡œë‚˜", "covid", "ë°±ì‹ ", "ê²€ì—­", "ê²©ë¦¬", "ë´‰ì‡„"
    ]
    has_safety = any(keyword in question for keyword in safety_keywords)
    
    # ê°€ê²©/ë¹„ìš© ë¹„êµ ê´€ë ¨ í‚¤ì›Œë“œ (ì›¹ ê²€ìƒ‰ í•„ìš”)
    price_keywords = [
        "ê°€ê²©", "ë¹„ìš©", "ìš”ê¸ˆ", "ë³´í—˜ë£Œ", "ë¹„êµ", "ì°¨ì´", "ì–¼ë§ˆ",
        "ì €ë ´", "ë¹„ì‹¸", "ê²½ìŸ", "ì‹œì¥", "í˜„ì¬ ê°€ê²©", "ìµœì‹  ê°€ê²©",
        "ê°€ê²© ë¹„êµ", "ë¹„ìš© ë¹„êµ", "ìš”ê¸ˆ ë¹„êµ", "ë³´í—˜ë£Œ ë¹„êµ",
        "ê°€ì¥ ì €ë ´", "ê°€ì¥ ë¹„ì‹¼", "ìˆœì„œ", "ìˆœìœ„", "ë­í‚¹", "í˜„ì¬",
        "ì‹¤ì‹œê°„", "ìµœì‹ ", "ì—…ë°ì´íŠ¸", "ë³€ë™", "ì‹œì„¸", "ë¹„êµí•´ì£¼ì„¸ìš”",
        "ë¹„êµí•´", "ë¹„êµí•´ì¤˜", "ë¹„êµí•´ì£¼ì‹œê³ ", "ë¹„êµí•´ì£¼ì„¸ìš”"
    ]
    
    # í˜œíƒ/ì´ë²¤íŠ¸ ê´€ë ¨ í‚¤ì›Œë“œ (ì›¹ ê²€ìƒ‰ í•„ìš” - ìµœì‹  ì •ë³´)
    benefit_keywords = [
        "í˜ì´ë°±", "ìºì‹œë°±", "ë¦¬ì›Œë“œ", "ì ë¦½", "í• ì¸", "í˜œíƒ", "ì´ë²¤íŠ¸",
        "í”„ë¡œëª¨ì…˜", "íŠ¹ê°€", "ì„¸ì¼", "ì¿ í°", "í¬ì¸íŠ¸", "ì ë¦½ê¸ˆ", "í˜„ê¸ˆ",
        "í˜„ê¸ˆí™”", "ì§€ê¸‰", "ì§€ì›", "ë³´ìƒ", "ì¸ì„¼í‹°ë¸Œ", "ì¶”ê°€í˜œíƒ",
        "ì‹ ê·œê³ ê°", "ì²«ê°€ì…", "ê°€ì…í˜œíƒ", "ì‹ ê·œí˜œíƒ", "íŠ¹ë³„í˜œíƒ"
    ]
    has_price = any(keyword in question for keyword in price_keywords)
    has_benefit = any(keyword in question for keyword in benefit_keywords)
    
    # ì›¹ ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨ ë¡œì§
    web_score = 0
    
    # ë‚ ì§œ ì •ë³´ê°€ ìˆìœ¼ë©´ +3
    if has_date:
        web_score += 3
    
    # ì§€ì—­ ì •ë³´ê°€ ìˆìœ¼ë©´ +3
    if has_city:
        web_score += 3
    
    # ì‹¤ì‹œê°„ ì •ë³´ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ +4
    if has_live:
        web_score += 4
    
    # ì•ˆì „ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ +3
    if has_safety:
        web_score += 3
    
    # ê°€ê²©/ë¹„ìš© ë¹„êµ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ +4 (ì‹¤ì‹œê°„ ê°€ê²© ì •ë³´ í•„ìš”)
    if has_price:
        web_score += 4
    
    # í˜œíƒ/ì´ë²¤íŠ¸ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ +5 (ìµœì‹  í˜œíƒ ì •ë³´ í•„ìš”)
    if has_benefit:
        web_score += 5
    
    # Recommend intentì´ë©´ì„œ ì§€ì—­/ë‚ ì§œ/ì‹¤ì‹œê°„ ì •ë³´ê°€ ìˆìœ¼ë©´ +2
    if intent == "recommend" and (has_city or has_date or has_live):
        web_score += 2
    
    # Compare intentì´ë©´ì„œ ê°€ê²© ë¹„êµ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ +3
    if intent == "compare" and has_price:
        web_score += 3
    
    # íŠ¹ì • íŒ¨í„´ë“¤
    if any(pattern in question for pattern in ["ì–´ë–¤ ë³´í—˜ì´", "ì–´ë–¤ ìƒí’ˆì´", "ì¶”ì²œí•´ì£¼ì„¸ìš”"]):
        if has_city or has_date:
            web_score += 3
    
    # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶”ê°€
    logger.debug(f"ì›¹ ê²€ìƒ‰ ì ìˆ˜ ê³„ì‚°: {web_score}ì  (ë‚ ì§œ:{has_date}, ì§€ì—­:{has_city}, ì‹¤ì‹œê°„:{has_live}, ì•ˆì „:{has_safety}, ê°€ê²©:{has_price}, í˜œíƒ:{has_benefit}, intent:{intent})")
    
    # ì›¹ ê²€ìƒ‰ í•„ìš”ì„± ì„ê³„ê°’ (5ì  ì´ìƒì´ë©´ ì›¹ ê²€ìƒ‰ í•„ìš”)
    return web_score >= 5

def _needs_llm_classification(question: str) -> bool:
    """
    ë³µì¡í•œ ì¼€ì´ìŠ¤ì¸ì§€ íŒë‹¨í•˜ì—¬ LLM ë¶„ë¥˜ê°€ í•„ìš”í•œì§€ ê²°ì •
    """
    # ì‹œìŠ¤í…œ ì„¤ì •ì—ì„œ ì„ê³„ê°’ ê°€ì ¸ì˜¤ê¸°
    config = get_system_config()
    threshold = config.get_complex_case_threshold()
    
    # ë³µì¡í•œ íŒ¨í„´ë“¤ (LLMì´ ë” ì •í™•í•  ìˆ˜ ìˆëŠ” ê²½ìš°)
    complex_patterns = [
        # ëª¨í˜¸í•œ ì§ˆë¬¸
        "ì–´ë–¤", "ì–´ëŠ", "ë¬´ì—‡", "ë­", "ì–´ë–»ê²Œ", "ì™œ", "ì–¸ì œ", "ì–´ë””ì„œ",
        # ë³µí•© ì§ˆë¬¸
        "ê·¸ë¦¬ê³ ", "ë˜í•œ", "ë˜ëŠ”", "ê·¸ëŸ°ë°", "í•˜ì§€ë§Œ", "ê·¸ëŸ¬ë‚˜",
        # ë¹„êµ ê´€ë ¨
        "ì°¨ì´", "ë‹¤ë¥¸", "ë¹„êµ", "ëŒ€ë¹„", "vs", "ëŒ€ì¡°",
        # ì¶”ì²œ ê´€ë ¨
        "ì¶”ì²œ", "ê¶Œì¥", "ì–´ë–¤ ê²Œ", "ì–´ë–¤ ê²ƒì´", "ì„ íƒ",
        # ìš”ì•½ ê´€ë ¨
        "ìš”ì•½", "ì •ë¦¬", "í•µì‹¬", "ì£¼ìš”", "ê°œìš”"
    ]
    
    # ë³µì¡í•œ í‚¤ì›Œë“œê°€ ì„ê³„ê°’ ì´ìƒ ìˆìœ¼ë©´ LLM ì‚¬ìš©
    complex_count = sum(1 for pattern in complex_patterns if pattern in question)
    return complex_count >= threshold

def _is_llm_result_better(fallback_result: Dict[str, Any], llm_result: Dict[str, Any]) -> bool:
    """
    LLM ê²°ê³¼ê°€ fallback ê²°ê³¼ë³´ë‹¤ ë” ì •í™•í•œì§€ íŒë‹¨
    """
    # LLM ê²°ê³¼ê°€ ë” êµ¬ì²´ì ì¸ reasoningì„ ì œê³µí•˜ë©´ ìš°ì„ 
    if len(llm_result.get("reasoning", "")) > len(fallback_result.get("reasoning", "")):
        return True
    
    # LLMì´ ë” êµ¬ì²´ì ì¸ intentë¥¼ ì œê³µí•˜ë©´ ìš°ì„ 
    llm_intent = llm_result.get("intent", "")
    fallback_intent = fallback_result.get("intent", "")
    
    # íŠ¹ì • intentì— ëŒ€í•œ ìš°ì„ ìˆœìœ„
    intent_priority = {"recommend": 4, "compare": 3, "summary": 2, "qa": 1}
    
    llm_priority = intent_priority.get(llm_intent, 0)
    fallback_priority = intent_priority.get(fallback_intent, 0)
    
    return llm_priority > fallback_priority

def planner_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    LLM ê¸°ë°˜ ì§ˆë¬¸ ë¶„ì„ ë° ë¶„ê¸° ê²°ì • (ì •í™•ë„ í–¥ìƒ: LLM ë¶„ë¥˜ ìš°ì„  ì‚¬ìš©)
    ë³´í—˜ì‚¬ ì—”í‹°í‹° ì¶”ì¶œ ë° í•„í„°ë§ ë¡œì§ í¬í•¨
    ì—¬í–‰ì ë³´í—˜ ë„ë©”ì¸ ê´€ë ¨ ì§ˆë¬¸ì´ ì•„ë‹Œ ê²½ìš° ë°”ë¡œ qa ë…¸ë“œë¡œ ë¼ìš°íŒ…
    """
    q = state.get("question", "")
    replan_count = state.get("replan_count", 0)
    
    # ì¬ê²€ìƒ‰ íšŸìˆ˜ ë¡œê¹…
    if replan_count > 0:
        logger.info(f"ì¬ê²€ìƒ‰ìœ¼ë¡œ ì¸í•œ planner ì¬ì‹¤í–‰ - ì¬ê²€ìƒ‰ íšŸìˆ˜: {replan_count}")
    
    # LLM ë¶„ë¥˜ ìš°ì„  ì‚¬ìš© (ë„ë©”ì¸ ê´€ë ¨ì„± í¬í•¨)
    logger.debug("LLM ë¶„ë¥˜ ìš°ì„  ì‚¬ìš© (ë„ë©”ì¸ ê´€ë ¨ì„± í¬í•¨)")
    try:
        classification = _llm_classify_intent(q)
        logger.debug("LLM ë¶„ë¥˜ ì„±ê³µ")
    except Exception as e:
        logger.warning(f"LLM ë¶„ë¥˜ ì‹¤íŒ¨, fallback ì‚¬ìš©: {str(e)}")
        classification = _fallback_classify(q)
    
    # LLM ë¶„ë¥˜ ê²°ê³¼ì—ì„œ ë„ë©”ì¸ ê´€ë ¨ì„± í™•ì¸
    is_domain_related = classification["is_domain_related"]
    logger.info(f"ë„ë©”ì¸ ê´€ë ¨ì„± ê²€ì‚¬: {is_domain_related}")
    
    # ì—¬í–‰ì ë³´í—˜ ë„ë©”ì¸ê³¼ ê´€ë ¨ë˜ì§€ ì•Šì€ ì§ˆë¬¸ì¸ ê²½ìš° ë°”ë¡œ qa ë…¸ë“œë¡œ ë¼ìš°íŒ…
    if not is_domain_related:
        logger.info(f"ğŸš« ë¹„ë„ë©”ì¸ ì§ˆë¬¸ ê°ì§€ - ë°”ë¡œ qa ë…¸ë“œë¡œ ë¼ìš°íŒ…: '{q}'")
        return {
            **state,
            "intent": "qa",
            "classification_reasoning": classification.get("reasoning", "ì—¬í–‰ì ë³´í—˜ ë„ë©”ì¸ê³¼ ê´€ë ¨ë˜ì§€ ì•Šì€ ì§ˆë¬¸ìœ¼ë¡œ ì¼ë°˜ LLM ë‹µë³€ ì œê³µ"),
            "is_domain_related": False,
            "insurer_filter": None,
            "extracted_insurers": [],
            "owned_insurers": [],
            "non_owned_insurers": [],
            "replan_count": replan_count,
            "max_replan_attempts": state.get("max_replan_attempts", 3)
        }
    
    # ì—¬í–‰ì ë³´í—˜ ë„ë©”ì¸ ê´€ë ¨ ì§ˆë¬¸ì¸ ê²½ìš° ê¸°ì¡´ ë¡œì§ ìˆ˜í–‰
    logger.info(f"âœ… ë„ë©”ì¸ ê´€ë ¨ ì§ˆë¬¸ - RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: '{q}'")
    
    # ë³´í—˜ì‚¬ ì—”í‹°í‹° ì¶”ì¶œ ë° needs_web ê²°ì •
    insurer_info = _determine_insurer_filter_and_web_need(q)
    logger.info(f"ë³´í—˜ì‚¬ ì¶”ì¶œ ê²°ê³¼: {insurer_info}")
    
    # ë””ë²„ê¹…ì„ ìœ„í•œ ìƒì„¸ ë¡œê·¸
    logger.info(f"ì§ˆë¬¸: '{q}'")
    logger.info(f"ì¶”ì¶œëœ ë³´í—˜ì‚¬: {insurer_info['extracted_insurers']}")
    logger.info(f"ë³´ìœ  ë³´í—˜ì‚¬: {insurer_info['owned_insurers']}")
    logger.info(f"ë¹„ë³´ìœ  ë³´í—˜ì‚¬: {insurer_info['non_owned_insurers']}")
    logger.info(f"ë³´í—˜ì‚¬ ê¸°ë°˜ needs_web: {insurer_info['needs_web']}")
    
    # ì´ë¯¸ ìœ„ì—ì„œ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ë°›ì•˜ìœ¼ë¯€ë¡œ ì¬ì‚¬ìš©
    intent = classification["intent"]
    
    # 2ë²ˆì§¸ ì‚¬ì´í´ì—ì„œëŠ” ë¬´ì¡°ê±´ needs_webì„ Trueë¡œ ì„¤ì •
    if replan_count >= 1:
        needs_web = True
        logger.info(f"ğŸ”„ 2ë²ˆì§¸ ì‚¬ì´í´ ì´ìƒ - ë¬´ì¡°ê±´ ì›¹ ê²€ìƒ‰ í™œì„±í™” (ì¬ê²€ìƒ‰ íšŸìˆ˜: {replan_count})")
    else:
        # ë³´í—˜ì‚¬ ì •ë³´ì™€ í‚¤ì›Œë“œ ê¸°ë°˜ needs_webì„ OR ì¡°ê±´ìœ¼ë¡œ ê²°í•©
        # ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ Trueë©´ ì›¹ ê²€ìƒ‰ í•„ìš”
        insurer_based_web = insurer_info["needs_web"]
        keyword_based_web = classification["needs_web"]
        needs_web = insurer_based_web or keyword_based_web
        
        logger.info(f"ì›¹ ê²€ìƒ‰ í•„ìš”ì„± ê²°ì •:")
        logger.info(f"  ë³´í—˜ì‚¬ ê¸°ë°˜: {insurer_based_web} (ì¶”ì¶œëœ ë³´í—˜ì‚¬: {insurer_info['extracted_insurers']})")
        logger.info(f"  í‚¤ì›Œë“œ ê¸°ë°˜: {keyword_based_web} (intent: {intent})")
        logger.info(f"  ìµœì¢… ê²°ì •: {needs_web} (OR ì¡°ê±´)")
    
    reasoning = classification.get("reasoning", "")
    
    return {
        **state, 
        "intent": intent, 
        "needs_web": needs_web, 
        "classification_reasoning": reasoning,
        "is_domain_related": True,  # ë„ë©”ì¸ ê´€ë ¨ ì§ˆë¬¸ì„ì„ ëª…ì‹œ
        # ë³´í—˜ì‚¬ í•„í„° ì •ë³´ ì¶”ê°€
        "insurer_filter": insurer_info["insurer_filter"],
        "extracted_insurers": insurer_info["extracted_insurers"],
        "owned_insurers": insurer_info["owned_insurers"],
        "non_owned_insurers": insurer_info["non_owned_insurers"],
        # replan_countëŠ” ëª…ì‹œì ìœ¼ë¡œ ìœ ì§€ (ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ)
        "replan_count": replan_count,
        "max_replan_attempts": state.get("max_replan_attempts", 3)  # ê¸°ë³¸ê°’ 3ìœ¼ë¡œ ì„¤ì •
    }