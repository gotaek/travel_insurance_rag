from typing import Dict, Any, List
import json
import logging
from app.deps import get_reevaluate_llm
from graph.models import QualityEvaluationResponse
from graph.config_manager import get_system_config

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ìƒìˆ˜ ì •ì˜ (ê¸°ë³¸ê°’, ì‹¤ì œë¡œëŠ” ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´)
QUALITY_THRESHOLD = 0.7
MAX_REPLAN_ATTEMPTS = 2

def reevaluate_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    LLM ê¸°ë°˜ ë‹µë³€ í’ˆì§ˆ í‰ê°€ ë° ì¬ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨ (ë¬´í•œë£¨í”„ ë°©ì§€ í¬í•¨)
    """
    # ì‹œìŠ¤í…œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    config = get_system_config()
    
    question = state.get("question", "")
    answer = state.get("draft_answer", {})
    citations = state.get("citations", [])
    passages = state.get("refined", [])
    replan_count = state.get("replan_count", 0)
    max_attempts = state.get("max_replan_attempts", config.get_max_replan_attempts())
    quality_threshold = config.get_quality_threshold()
    max_structured_failures = config.get_max_structured_failures()
    is_domain_related = state.get("is_domain_related", True)  # ë„ë©”ì¸ ê´€ë ¨ì„± í™•ì¸
    
    logger.info(f"ğŸ” [Reevaluate] ì‹œì‘ - ì¬ê²€ìƒ‰ íšŸìˆ˜: {replan_count}/{max_attempts}")
    logger.info(f"ğŸ” [Reevaluate] ì§ˆë¬¸: '{question[:100]}...'")
    logger.info(f"ğŸ” [Reevaluate] ë‹µë³€ íƒ€ì…: {type(answer)}, ì¸ìš© ìˆ˜: {len(citations)}, íŒ¨ì‹œì§€ ìˆ˜: {len(passages)}")
    logger.info(f"ğŸ” [Reevaluate] ë„ë©”ì¸ ê´€ë ¨ì„±: {is_domain_related}")
    
    # ë¹„ë„ë©”ì¸ ì§ˆë¬¸ì¸ ê²½ìš° í’ˆì§ˆ í‰ê°€ë¥¼ ê±´ë„ˆë›°ê³  ë°”ë¡œ í†µê³¼
    if not is_domain_related:
        logger.info(f"ğŸ” [Reevaluate] ë¹„ë„ë©”ì¸ ì§ˆë¬¸ - í’ˆì§ˆ í‰ê°€ ê±´ë„ˆë›°ê³  ë°”ë¡œ í†µê³¼")
        return {
            **state,
            "quality_score": 1.0,  # ìµœê³  ì ìˆ˜ë¡œ ì„¤ì •
            "quality_feedback": "ë¹„ë„ë©”ì¸ ì§ˆë¬¸ìœ¼ë¡œ í’ˆì§ˆ í‰ê°€ë¥¼ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.",
            "needs_replan": False,  # ì¬ê²€ìƒ‰ ë¶ˆí•„ìš”
            "replan_query": "",
            "final_answer": answer  # í˜„ì¬ ë‹µë³€ì„ ìµœì¢… ë‹µë³€ìœ¼ë¡œ ì„¤ì •
        }
    
    # ë‹µë³€ í…ìŠ¤íŠ¸ ì¶”ì¶œ - ë‹¤ì–‘í•œ ë‹µë³€ êµ¬ì¡° ì§€ì›
    if isinstance(answer, dict):
        # conclusion í•„ë“œê°€ ìˆìœ¼ë©´ ì‚¬ìš© (summarize, qa, compare, recommend ë…¸ë“œ)
        answer_text = answer.get("conclusion", "")
        # conclusionì´ ì—†ìœ¼ë©´ text í•„ë“œ ì‚¬ìš© (ê¸°ì¡´ í˜¸í™˜ì„±)
        if not answer_text:
            answer_text = answer.get("text", "")
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ì „ì²´ ë‹µë³€ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        if not answer_text:
            answer_text = str(answer)
    else:
        answer_text = str(answer)
    
    # ê¸´ê¸‰ íƒˆì¶œ ë¡œì§: ì—°ì† êµ¬ì¡°í™” ì‹¤íŒ¨ ê°ì§€
    structured_failure_count = state.get("structured_failure_count", 0)
    emergency_fallback_used = state.get("emergency_fallback_used", False)
    
    # ì„±ëŠ¥ ìµœì í™”: ìµœëŒ€ ì¬ê²€ìƒ‰ íšŸìˆ˜ì— ë„ë‹¬í•˜ë©´ í’ˆì§ˆ í‰ê°€ ì—†ì´ ë°”ë¡œ ë‹µë³€ ì œê³µ
    if replan_count >= max_attempts:
        logger.warning(f"ğŸš¨ [Reevaluate] ì¬ê²€ìƒ‰ íšŸìˆ˜ê°€ {replan_count}íšŒì— ë„ë‹¬ - í’ˆì§ˆ í‰ê°€ ì—†ì´ ë‹µë³€ ì™„ë£Œ")
        return {
            **state,
            "needs_replan": False,
            "final_answer": answer,
            "quality_feedback": f"ì¬ê²€ìƒ‰ íšŸìˆ˜({replan_count}íšŒ) ì´ˆê³¼ë¡œ ë‹µë³€ì„ ì™„ë£Œí•©ë‹ˆë‹¤.",
            "replan_count": replan_count
        }
    
    # ê¸´ê¸‰ íƒˆì¶œ: ì—°ì† êµ¬ì¡°í™” ì‹¤íŒ¨ê°€ ì„ê³„ê°’ì— ë„ë‹¬í•œ ê²½ìš°
    if structured_failure_count >= max_structured_failures or emergency_fallback_used:
        logger.warning(f"ğŸš¨ [Reevaluate] ì—°ì† êµ¬ì¡°í™” ì‹¤íŒ¨ ì„ê³„ê°’ ë„ë‹¬({structured_failure_count}/{max_structured_failures}) - ê¸´ê¸‰ íƒˆì¶œ")
        return {
            **state,
            "needs_replan": False,
            "final_answer": answer,
            "quality_feedback": f"ì—°ì† êµ¬ì¡°í™” ì‹¤íŒ¨({structured_failure_count}íšŒ)ë¡œ ì¸í•œ ê¸´ê¸‰ íƒˆì¶œ",
            "replan_count": replan_count,
            "emergency_fallback_used": True
        }
    
    # LLMì„ ì‚¬ìš©í•œ í’ˆì§ˆ í‰ê°€ (ê¸´ê¸‰ íƒˆì¶œ ì„ê³„ê°’ ì´ì „ì—ë§Œ)
    logger.info(f"ğŸ” [Reevaluate] ë‹µë³€ í’ˆì§ˆ í‰ê°€ ì‹œì‘ - ì§ˆë¬¸: {question[:50]}... (ì¬ê²€ìƒ‰ íšŸìˆ˜: {replan_count})")
    logger.debug(f"ğŸ” [Reevaluate] ì¶”ì¶œëœ ë‹µë³€ í…ìŠ¤íŠ¸: {answer_text[:100]}..." if answer_text else "ë‹µë³€ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ")
    logger.debug(f"ğŸ” [Reevaluate] ë‹µë³€ ì›ë³¸ íƒ€ì…: {type(answer)}, ë‚´ìš©: {str(answer)[:100]}...")
    quality_result = _evaluate_answer_quality(question, answer_text, citations, passages, quality_threshold)
    
    # ì¬ê²€ìƒ‰ íšŸìˆ˜ ì²´í¬ ë° ë¬´í•œë£¨í”„ ë°©ì§€
    needs_replan = quality_result["needs_replan"] and replan_count < max_attempts
    
    # ë¬´í•œë£¨í”„ ë°©ì§€: ìµœëŒ€ ì‹œë„ íšŸìˆ˜ì— ë„ë‹¬í•˜ë©´ ê°•ì œë¡œ ë‹µë³€ ì™„ë£Œ (3ë²ˆì§¸ ì‚¬ì´í´ ì´í›„)
    if replan_count >= max_attempts:
        needs_replan = False
        logger.warning(f"ğŸš¨ [Reevaluate] ìµœëŒ€ ì¬ê²€ìƒ‰ íšŸìˆ˜({max_attempts})ì— ë„ë‹¬í•˜ì—¬ ë‹µë³€ì„ ì™„ë£Œí•©ë‹ˆë‹¤.")
        quality_result["score"] = max(quality_result["score"], 0.5)  # ìµœì†Œ 0.5ì  ë³´ì¥
        print(f"ğŸš¨ reevaluateì—ì„œ ê°•ì œ ì™„ë£Œ - replan_count: {replan_count}, max_attempts: {max_attempts}")
    
    # ë‹µë³€ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ê²½ìš° ìµœì†Œ ì ìˆ˜ ë³´ì¥
    if answer_text and answer_text.strip() and quality_result["score"] < 0.3:
        logger.warning(f"ğŸ” [Reevaluate] ë‹µë³€ì´ ì¡´ì¬í•˜ì§€ë§Œ ë‚®ì€ ì ìˆ˜({quality_result['score']:.2f}) - ìµœì†Œ ì ìˆ˜ 0.3ìœ¼ë¡œ ì¡°ì •")
        quality_result["score"] = 0.3
        if quality_result["score"] >= quality_threshold:
            needs_replan = False
    
    # 2ë²ˆì§¸ ì‚¬ì´í´ì—ì„œëŠ” ë¬´ì¡°ê±´ ë‹µë³€ ì œê³µ (ê´€ëŒ€í•œ í‰ê°€)
    if replan_count >= 1 and answer_text and answer_text.strip():
        logger.warning(f"ğŸ” [Reevaluate] 2ë²ˆì§¸ ì‚¬ì´í´ ì´ìƒ - ë¬´ì¡°ê±´ ë‹µë³€ ì œê³µ (ì¬ê²€ìƒ‰ íšŸìˆ˜: {replan_count})")
        quality_result["score"] = max(quality_result["score"], 0.8)  # ë†’ì€ ì ìˆ˜ë¡œ ì„¤ì •
        needs_replan = False  # ì¬ê²€ìƒ‰ ì¤‘ë‹¨
        logger.info(f"ğŸ” [Reevaluate] 2ë²ˆì§¸ ì‚¬ì´í´ ë‹µë³€ ì œê³µ - ì ìˆ˜: {quality_result['score']:.2f}")
    
    logger.info(f"ğŸ” [Reevaluate] í’ˆì§ˆ ì ìˆ˜: {quality_result['score']:.2f}, ì¬ê²€ìƒ‰ í•„ìš”: {needs_replan}, ì¬ê²€ìƒ‰ íšŸìˆ˜: {replan_count}/{max_attempts}")
    
    return {
        **state,
        "quality_score": quality_result["score"],
        "quality_feedback": quality_result["feedback"],
        "needs_replan": needs_replan,
        "replan_query": quality_result["replan_query"],
        "final_answer": answer if quality_result["score"] >= quality_threshold or replan_count >= max_attempts else None
    }

def _evaluate_answer_quality(question: str, answer: str, citations: List[Dict[str, Any]], passages: List[Dict[str, Any]], quality_threshold: float = 0.7) -> Dict[str, Any]:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ í’ˆì§ˆì„ í‰ê°€í•˜ê³  ì¬ê²€ìƒ‰ í•„ìš”ì„±ì„ íŒë‹¨
    """
    prompt = f"""
ë‹¤ìŒì€ ì—¬í–‰ìë³´í—˜ RAG ì‹œìŠ¤í…œì˜ ì§ˆë¬¸-ë‹µë³€ ìŒì…ë‹ˆë‹¤. ë‹µë³€ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ê³  ì¬ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: "{question}"

ë‹µë³€: "{answer}"

ì¸ìš© ì •ë³´: {len(citations)}ê°œ
ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(passages)}ê°œ

**í‰ê°€ ì‹œ ì£¼ì˜ì‚¬í•­**:
- ë‹µë³€ì´ ì™„ë²½í•˜ì§€ ì•Šì•„ë„, ì§ˆë¬¸ì— ë¶€ë¶„ì ìœ¼ë¡œë¼ë„ ê´€ë ¨ëœ ë‚´ìš©ì„ ë‹´ê³  ìˆìœ¼ë©´ ì ìˆ˜ë¥¼ ì£¼ì„¸ìš”.
- ë‹µë³€ì´ ë¹„ì–´ìˆì§€ ì•Šë‹¤ë©´ ê¸°ë³¸ì ìœ¼ë¡œ 0.5ì  ì´ìƒì„ ë¶€ì—¬í•´ì£¼ì„¸ìš”.
- ì¸ìš©ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ì™„ì „ì„±ì´ ë–¨ì–´ì ¸ë„, ë‹µë³€ì´ ì¼ì • ë¶€ë¶„ ìœ ìš©í•˜ë©´ ì¬ê²€ìƒ‰ ì—†ì´ ê·¸ëŒ€ë¡œ ì¸ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

í‰ê°€ ê¸°ì¤€ (ê° 0-1):
1. **ì •í™•ì„±**: ì§ˆë¬¸ì— ì–´ëŠ ì •ë„ë¼ë„ ì •í™•íˆ ë‹µí•˜ê³  ìˆëŠ”ê°€?
2. **ì™„ì „ì„±**: ë‹µë³€ì´ ì¶©ë¶„íˆ ìƒì„¸í•˜ê±°ë‚˜, ìµœì†Œí•œ í•µì‹¬ì€ ì „ë‹¬ë˜ëŠ”ê°€?
3. **ê´€ë ¨ì„±**: ì—¬í–‰ìë³´í—˜ ë„ë©”ì¸ê³¼ ê´€ë ¨ëœ ë‹µë³€ì¸ê°€?
4. **ì¸ìš© í’ˆì§ˆ**: ì ì ˆí•œ ì¸ìš©ì´ ìˆëŠ”ê°€? (ì—†ì–´ë„ ê°ì ì€ í•˜ë˜ 0ì ì€ ì•„ë‹˜)

ì´ ì ìˆ˜ëŠ” 0-1 ì‚¬ì´ ê°’ìœ¼ë¡œ, 0.5 ì´ìƒì´ë©´ ê¸°ë³¸ì ìœ¼ë¡œ "ìˆ˜ìš© ê°€ëŠ¥", 0.7 ì´ìƒì´ë©´ "ì–‘í˜¸"ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.

**ì¬ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°** (ë” ì™„í™”ëœ ê¸°ì¤€):
- ë‹µë³€ì´ ì™„ì „íˆ ë¹„ì–´ ìˆê±°ë‚˜ ë¬´ì˜ë¯¸í•œ ê²½ìš°
- ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ì „í˜€ ë¬´ê´€í•œ ê²½ìš°
- ë‹µë³€ì´ ì§€ë‚˜ì¹˜ê²Œ ëª¨í˜¸í•˜ê±°ë‚˜ ì˜¤í•´ë¥¼ ë¶ˆëŸ¬ì˜¬ ì •ë„ë¡œ ë¶ˆì™„ì „í•œ ê²½ìš°
- ë°˜ë“œì‹œ ìµœì‹  ì •ë³´(ì˜ˆ: ì—¬í–‰ì§€ í˜„í™©, ë‰´ìŠ¤ ë“±)ê°€ í•„ìš”í•œ ì§ˆë¬¸ì¸ë° ìµœì‹ ì„±ì´ ì—†ëŠ” ê²½ìš°

ì¶œë ¥ í˜•ì‹(JSON):
- score: 0.0~1.0 ì‚¬ì´ í’ˆì§ˆ ì ìˆ˜
- feedback: í’ˆì§ˆ í‰ê°€ ìƒì„¸ ì„¤ëª…
- needs_replan: true/false
- replan_query: ì¬ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš° ìƒˆë¡œìš´ ê²€ìƒ‰ ì§ˆë¬¸ (ì—†ìœ¼ë©´ null)
"""

    try:
        logger.debug("LLMì„ ì‚¬ìš©í•œ í’ˆì§ˆ í‰ê°€ ì‹œì‘ (structured output)")
        llm = get_reevaluate_llm()  # Reevaluate ì „ìš© LLM ì‚¬ìš© (Gemini 2.5 Flash-Lite)
        
        # structured output ì‚¬ìš©
        structured_llm = llm.with_structured_output(QualityEvaluationResponse)
        response = structured_llm.generate_content(prompt)
        
        logger.debug(f"Structured LLM ì‘ë‹µ: {response}")
        
        # ìœ íš¨ì„± ê²€ì¦
        score = response.score
        if not isinstance(score, (int, float)) or score < 0 or score > 1:
            logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ ì ìˆ˜: {score}, ê¸°ë³¸ê°’ 0.5 ì‚¬ìš©")
            score = 0.5
            
        needs_replan = response.needs_replan
        if not isinstance(needs_replan, bool):
            needs_replan = score < quality_threshold
            logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ needs_replan: {needs_replan}, ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì„¤ì •")
            
        replan_query = response.replan_query
        if replan_query == "null" or replan_query is None:
            replan_query = ""
            
        return {
            "score": float(score),
            "feedback": response.feedback,
            "needs_replan": needs_replan,
            "replan_query": replan_query
        }
        
    except Exception as e:
        logger.error(f"LLM í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨, fallback ì‚¬ìš©: {str(e)}")
        return _fallback_evaluate(question, answer, citations, passages, quality_threshold)

def _fallback_evaluate(question: str, answer: str, citations: List[Dict[str, Any]], passages: List[Dict[str, Any]], quality_threshold: float = 0.7) -> Dict[str, Any]:
    """
    LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•˜ëŠ” ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± í‰ê°€
    """
    # ë‹µë³€ì´ ì‹¤ì œë¡œ ë¹„ì–´ìˆëŠ”ì§€ ì²´í¬
    if not answer or answer.strip() == "":
        logger.warning("ë‹µë³€ì´ ë¹„ì–´ìˆìŒ - Fallback í‰ê°€ì—ì„œ 0ì  ì²˜ë¦¬")
        return {
            "score": 0.0,
            "feedback": "ë‹µë³€ì´ ë¹„ì–´ìˆì–´ ì •í™•ì„±, ì™„ì „ì„±, ê´€ë ¨ì„± ëª¨ë‘ 0ì ì…ë‹ˆë‹¤.",
            "needs_replan": True,
            "replan_query": question
        }
    
    # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚° (ë‹µë³€ì´ ìˆìœ¼ë©´ ìµœì†Œ 0.3ì )
    score = 0.3
    
    # ë‹µë³€ ê¸¸ì´ ì²´í¬
    if len(answer) > 50:
        score += 0.2
    elif len(answer) > 20:
        score += 0.1
    
    # ì¸ìš© ì •ë³´ ì²´í¬
    if len(citations) > 0:
        score += 0.2
    
    # ê²€ìƒ‰ëœ ë¬¸ì„œ ì²´í¬
    if len(passages) > 0:
        score += 0.1
    
    # í‚¤ì›Œë“œ ë§¤ì¹­ ì²´í¬
    question_words = set(question.lower().split())
    answer_words = set(answer.lower().split())
    if len(question_words.intersection(answer_words)) > 0:
        score += 0.2
    
    # ì ìˆ˜ ì œí•œ
    score = min(score, 1.0)
    
    needs_replan = score < quality_threshold
    replan_query = question if needs_replan else ""
    
    logger.info(f"Fallback í‰ê°€ ì™„ë£Œ - ì ìˆ˜: {score:.2f}, ì¬ê²€ìƒ‰ í•„ìš”: {needs_replan}")
    
    return {
        "score": score,
        "feedback": f"Fallback í‰ê°€: ë‹µë³€ê¸¸ì´({len(answer)}), ì¸ìš©({len(citations)}), ë¬¸ì„œ({len(passages)})",
        "needs_replan": needs_replan,
        "replan_query": replan_query
    }
