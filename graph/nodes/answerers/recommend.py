from typing import Dict, Any
import json
from pathlib import Path
from app.deps import get_llm
from graph.models import RecommendResponse, EvidenceInfo, CaveatInfo

def _load_prompt(prompt_name: str) -> str:
    """í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ"""
    # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
    current_dir = Path(__file__).parent.parent.parent
    prompt_path = current_dir / "prompts" / f"{prompt_name}.md"
    return prompt_path.read_text(encoding="utf-8")

def _format_context(passages: list) -> str:
    """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
    if not passages:
        return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    context_parts = []
    for i, passage in enumerate(passages[:5], 1):  # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©
        doc_id = passage.get("doc_id", "ì•Œ ìˆ˜ ì—†ìŒ")
        page = passage.get("page", "ì•Œ ìˆ˜ ì—†ìŒ")
        text = passage.get("text", "")[:500]  # 500ìë¡œ ì œí•œ
        context_parts.append(f"[ë¬¸ì„œ {i}] {doc_id} (í˜ì´ì§€ {page})\n{text}\n")
    
    return "\n".join(context_parts)

def _format_web_results(web_results: list) -> str:
    """ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…"""
    if not web_results:
        return "ì‹¤ì‹œê°„ ë‰´ìŠ¤ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    web_parts = []
    for i, result in enumerate(web_results[:3], 1):  # ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
        title = result.get("title", "ì œëª© ì—†ìŒ")
        snippet = result.get("snippet", "")[:200]  # 200ìë¡œ ì œí•œ
        web_parts.append(f"[ë‰´ìŠ¤ {i}] {title}\n{snippet}\n")
    
    return "\n".join(web_parts)

def _parse_llm_response_fallback(llm, prompt: str) -> Dict[str, Any]:
    """structured output ì‹¤íŒ¨ ì‹œ ì¼ë°˜ LLM í˜¸ì¶œë¡œ fallback"""
    try:
        print("ğŸ”„ Recommend ë…¸ë“œ fallback íŒŒì‹± ì‹œë„...")
        response = llm.generate_content(prompt)
        response_text = response.text
        
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ê¸°ë°˜ fallback
        return {
            "conclusion": response_text[:500] if response_text else "ì¶”ì²œì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.",
            "evidence": [EvidenceInfo(text="Fallback íŒŒì‹±ìœ¼ë¡œ ìƒì„±ëœ ë‹µë³€", source="Fallback ì‹œìŠ¤í…œ")],
            "caveats": [CaveatInfo(text="ì›ë³¸ structured outputì´ ì‹¤íŒ¨í•˜ì—¬ ì¼ë°˜ íŒŒì‹±ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.", source="Fallback ì‹œìŠ¤í…œ")],
            "quotes": [],
            "web_quotes": [],
            "recommendations": [],
            "web_info": {}
        }
        
    except Exception as fallback_error:
        print(f"âŒ Recommend ë…¸ë“œ fallbackë„ ì‹¤íŒ¨: {str(fallback_error)}")
        return {
            "conclusion": "ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "evidence": [EvidenceInfo(text=f"Fallback íŒŒì‹±ë„ ì‹¤íŒ¨: {str(fallback_error)[:100]}", source="Fallback ì‹œìŠ¤í…œ")],
            "caveats": [
                CaveatInfo(text=f"ìƒì„¸ ì˜¤ë¥˜: {str(fallback_error)}", source="Fallback ì‹œìŠ¤í…œ"),
                CaveatInfo(text="ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.", source="Fallback ì‹œìŠ¤í…œ")
            ],
            "quotes": [],
            "web_quotes": [],
            "recommendations": [],
            "web_info": {}
        }

def _parse_llm_response_structured(llm, prompt: str, emergency_fallback: bool = False) -> Dict[str, Any]:
    """LLM ì‘ë‹µì„ structured outputìœ¼ë¡œ íŒŒì‹±"""
    try:
        # structured output ì‚¬ìš© (ê¸´ê¸‰ íƒˆì¶œ ëª¨ë“œ ì§€ì›)
        structured_llm = llm.with_structured_output(RecommendResponse, emergency_fallback=emergency_fallback)
        response = structured_llm.generate_content(prompt)
        
        return {
            "conclusion": response.conclusion,
            "evidence": response.evidence,
            "caveats": response.caveats,
            "quotes": response.quotes,
            "web_quotes": response.web_quotes,
            "recommendations": response.recommendations,
            "web_info": response.web_info
        }
    except Exception as e:
        # structured output ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡°ë¡œ fallback
        error_str = str(e).lower()
        print(f"âŒ Recommend ë…¸ë“œ structured output ì‹¤íŒ¨: {str(e)}")
        
        if "quota" in error_str or "limit" in error_str or "429" in error_str or "exceeded" in error_str:
            return {
                "conclusion": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ API í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì–´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "evidence": [EvidenceInfo(text="Gemini API ì¼ì¼ í• ë‹¹ëŸ‰ ì´ˆê³¼", source="API ì‹œìŠ¤í…œ")],
                "caveats": [
                    CaveatInfo(text="ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", source="API ì‹œìŠ¤í…œ"),
                    CaveatInfo(text="API í• ë‹¹ëŸ‰ì´ ë³µêµ¬ë˜ë©´ ì •ìƒì ìœ¼ë¡œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", source="API ì‹œìŠ¤í…œ"),
                    CaveatInfo(text="ì˜¤ë¥˜ ì½”ë“œ: 429 (Quota Exceeded)", source="API ì‹œìŠ¤í…œ")
                ],
                "quotes": [],
                "recommendations": [],
                "web_info": {}
            }
        elif "404" in error_str or "publisher" in error_str or "model" in error_str:
            return {
                "conclusion": "ëª¨ë¸ ì„¤ì • ì˜¤ë¥˜ë¡œ ì¸í•´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "evidence": [EvidenceInfo(text="Gemini ëª¨ë¸ ì„¤ì • ì˜¤ë¥˜", source="API ì‹œìŠ¤í…œ")],
                "caveats": [
                    CaveatInfo(text="ëª¨ë¸ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.", source="API ì‹œìŠ¤í…œ"),
                    CaveatInfo(text="ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", source="API ì‹œìŠ¤í…œ")
                ],
                "quotes": [],
                "recommendations": [],
                "web_info": {}
            }
        else:
            # structured output ì‹¤íŒ¨ ì‹œ fallback íŒŒì‹± ì‹œë„
            return _parse_llm_response_fallback(llm, prompt)

def recommend_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    ì¶”ì²œ ì—ì´ì „íŠ¸: ì—¬í–‰ ì¼ì •, ì§€ì—­, ìµœì‹  ë‰´ìŠ¤ë¥¼ ê³ ë ¤í•˜ì—¬ ë§ì¶¤ íŠ¹ì•½ ì¶”ì²œ (verify_refine ì •ë³´ í™œìš©)
    """
    question = state.get("question", "")
    refined = state.get("refined", [])
    web_results = state.get("web_results", [])
    
    # verify_refineì—ì„œ ìƒì„±ëœ ì •ë³´ë“¤ í™œìš©
    citations = state.get("citations", [])
    warnings = state.get("warnings", [])
    verification_status = state.get("verification_status", "pass")
    policy_disclaimer = state.get("policy_disclaimer", "")
    metrics = state.get("metrics", {})
    
    print(f"ğŸ” [Recommend Node] ê²€ì¦ ìƒíƒœ: {verification_status}, ê²½ê³  ìˆ˜: {len(warnings)}, ì¸ìš© ìˆ˜: {len(citations)}")
    
    # ê¸´ê¸‰ íƒˆì¶œ ë¡œì§: ì—°ì† êµ¬ì¡°í™” ì‹¤íŒ¨ ê°ì§€
    structured_failure_count = state.get("structured_failure_count", 0)
    max_structured_failures = state.get("max_structured_failures", 2)
    emergency_fallback_used = state.get("emergency_fallback_used", False)
    
    # ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ… (refined ì‚¬ìš©)
    context = _format_context(refined)
    web_info = _format_web_results(web_results)
    
    # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    system_prompt = _load_prompt("system_core")
    recommend_prompt = _load_prompt("recommend")
    
    # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    full_prompt = f"""
        {system_prompt}

        {recommend_prompt}

        ## ì§ˆë¬¸
        {question}

        ## ì°¸ê³  ë¬¸ì„œ
        {context}

        ## ì‹¤ì‹œê°„ ë‰´ìŠ¤/ì •ë³´
        {web_info}

        ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë§ì¶¤ ì¶”ì²œì„ í•´ì£¼ì„¸ìš”.
        """
    
    try:
        # LLM í˜¸ì¶œ
        llm = get_llm()
        
        # ê¸´ê¸‰ íƒˆì¶œ ëª¨ë“œ ê²°ì •
        use_emergency_fallback = (structured_failure_count >= max_structured_failures) or emergency_fallback_used
        
        if use_emergency_fallback:
            print(f"ğŸš¨ [Recommend Node] ê¸´ê¸‰ íƒˆì¶œ ëª¨ë“œ í™œì„±í™” - êµ¬ì¡°í™” ì‹¤íŒ¨ íšŸìˆ˜: {structured_failure_count}/{max_structured_failures}")
        
        # structured output ì‚¬ìš© (ê¸´ê¸‰ íƒˆì¶œ ëª¨ë“œ ì§€ì›)
        answer = _parse_llm_response_structured(llm, full_prompt, emergency_fallback=use_emergency_fallback)
        
        # êµ¬ì¡°í™” ì‹¤íŒ¨ ê°ì§€ ë° ì¹´ìš´í„° ì—…ë°ì´íŠ¸
        is_empty_result = (
            not answer.get("conclusion") or 
            answer.get("conclusion", "").strip() == "" or
            answer.get("conclusion", "").strip() == "ì¶”ì²œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
        
        if is_empty_result and not use_emergency_fallback:
            # êµ¬ì¡°í™” ì‹¤íŒ¨ ì¹´ìš´í„° ì¦ê°€
            new_failure_count = structured_failure_count + 1
            print(f"âš ï¸ [Recommend Node] êµ¬ì¡°í™” ì‹¤íŒ¨ ê°ì§€ - ì¹´ìš´í„°: {new_failure_count}/{max_structured_failures}")
            
            # ì—°ì† ì‹¤íŒ¨ê°€ ì„ê³„ê°’ì— ë„ë‹¬í•˜ë©´ ê¸´ê¸‰ íƒˆì¶œ ëª¨ë“œë¡œ ì¬ì‹œë„
            if new_failure_count >= max_structured_failures:
                print(f"ğŸš¨ [Recommend Node] ì—°ì† êµ¬ì¡°í™” ì‹¤íŒ¨ ì„ê³„ê°’ ë„ë‹¬ - ê¸´ê¸‰ íƒˆì¶œ ëª¨ë“œë¡œ ì¬ì‹œë„")
                answer = _parse_llm_response_structured(llm, full_prompt, emergency_fallback=True)
                return {
                    **state, 
                    "draft_answer": answer, 
                    "final_answer": answer,
                    "structured_failure_count": new_failure_count,
                    "emergency_fallback_used": True
                }
            else:
                return {
                    **state, 
                    "draft_answer": answer, 
                    "final_answer": answer,
                    "structured_failure_count": new_failure_count
                }
        
        # verify_refineì˜ citations í™œìš© (ìš°ì„ ìˆœìœ„)
        if citations and not answer.get("quotes"):
            answer["quotes"] = [
                {
                    "text": c.get("snippet", "")[:200] + "...",
                    "source": f"{c.get('insurer', '')}_{c.get('doc_id', 'ì•Œ ìˆ˜ ì—†ìŒ')}_í˜ì´ì§€{c.get('page', '?')}"
                }
                for c in citations[:3]  # ìƒìœ„ 3ê°œë§Œ
            ]
            print(f"ğŸ” [Recommend Node] í‘œì¤€í™”ëœ ì¸ìš© ì •ë³´ ì¶”ê°€ - {len(answer['quotes'])}ê°œ")
        elif refined and not answer.get("quotes"):
            # fallback: refinedì—ì„œ ì§ì ‘ ìƒì„±
            answer["quotes"] = [
                {
                    "text": p.get("text", "")[:200] + "...",
                    "source": f"{p.get('insurer', 'ì•Œ ìˆ˜ ì—†ìŒ')}_{p.get('doc_id', 'ì•Œ ìˆ˜ ì—†ìŒ')}_í˜ì´ì§€{p.get('page', '?')}"
                }
                for p in refined[:3]  # ìƒìœ„ 3ê°œë§Œ
            ]
            print(f"ğŸ” [Recommend Node] fallback ì¶œì²˜ ì •ë³´ ì¶”ê°€ - {len(answer['quotes'])}ê°œ")
        
        # verify_refineì˜ warningsë¥¼ caveatsì— ë°˜ì˜
        if warnings:
            warning_caveats = [CaveatInfo(text=f"âš ï¸ {warning}", source="ê²€ì¦ ì‹œìŠ¤í…œ") for warning in warnings[:2]]  # ìƒìœ„ 2ê°œ ê²½ê³ ë§Œ
            answer["caveats"].extend(warning_caveats)
            print(f"ğŸ” [Recommend Node] ê²€ì¦ ê²½ê³  ë°˜ì˜ - {len(warning_caveats)}ê°œ")
        
        # policy_disclaimerë¥¼ caveatsì— ì¶”ê°€
        if policy_disclaimer:
            answer["caveats"].append(CaveatInfo(text=f"ğŸ“‹ {policy_disclaimer}", source="ë²•ì  ë©´ì±… ì¡°í•­"))
            print(f"ğŸ” [Recommend Node] ë²•ì  ë©´ì±… ì¡°í•­ ì¶”ê°€")
        
        # verification_statusì— ë”°ë¥¸ ë‹µë³€ ì¡°ì •
        if verification_status == "fail":
            answer["conclusion"] = "ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì •í™•í•œ ì¶”ì²œì„ ì œê³µí•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."
            answer["caveats"].append(CaveatInfo(text="ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", source="ê²€ì¦ ì‹œìŠ¤í…œ"))
            print(f"ğŸ” [Recommend Node] ê²€ì¦ ì‹¤íŒ¨ë¡œ ì¸í•œ ë‹µë³€ ì¡°ì •")
        elif verification_status == "warn":
            answer["caveats"].append(CaveatInfo(text="ì¼ë¶€ ì •ë³´ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ìƒì¶©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", source="ê²€ì¦ ì‹œìŠ¤í…œ"))
            print(f"ğŸ” [Recommend Node] ê²€ì¦ ê²½ê³ ë¡œ ì¸í•œ ì£¼ì˜ì‚¬í•­ ì¶”ê°€")
        
        # ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ web_quotesì— ì¶”ê°€ (ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ)
        if web_results and not answer.get("web_quotes"):
            answer["web_quotes"] = [
                {
                    "text": result.get("snippet", "")[:200] + "...",
                    "source": f"ì›¹ê²€ìƒ‰_{result.get('title', 'ì œëª© ì—†ìŒ')}_{result.get('url', 'URL ì—†ìŒ')}"
                }
                for result in web_results[:3]  # ìƒìœ„ 3ê°œë§Œ
            ]
        
        # web_info í•„ë“œê°€ Dict íƒ€ì…ì¸ ê²½ìš° WebInfo ê°ì²´ë¡œ ë³€í™˜
        if isinstance(answer.get("web_info"), dict):
            web_info_dict = answer["web_info"]
            answer["web_info"] = {
                "latest_news": web_info_dict.get("latest_news", ""),
                "travel_alerts": web_info_dict.get("travel_alerts", "")
            }
        elif not answer.get("web_info"):
            # web_infoê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
            answer["web_info"] = {
                "latest_news": "",
                "travel_alerts": ""
            }
        
        # ì„±ê³µ ì‹œ êµ¬ì¡°í™” ì‹¤íŒ¨ ì¹´ìš´í„° ë¦¬ì…‹
        return {
            **state, 
            "draft_answer": answer, 
            "final_answer": answer,
            "structured_failure_count": 0,
            "emergency_fallback_used": False
        }
        
    except Exception as e:
        # LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ fallback
        fallback_answer = {
            "conclusion": f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: '{question}'",
            "evidence": [EvidenceInfo(text="LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", source="ì‹œìŠ¤í…œ ì˜¤ë¥˜")],
            "caveats": [
                CaveatInfo(text="ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.", source="ì‹œìŠ¤í…œ ì˜¤ë¥˜"),
                CaveatInfo(text=f"ì˜¤ë¥˜: {str(e)}", source="ì‹œìŠ¤í…œ ì˜¤ë¥˜")
            ],
            "quotes": [],
            "web_quotes": [],
            "recommendations": [],
            "web_info": {}
        }
        return {**state, "draft_answer": fallback_answer, "final_answer": fallback_answer}